{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer","metadata":{"execution":{"iopub.status.busy":"2022-11-28T00:37:08.168400Z","iopub.execute_input":"2022-11-28T00:37:08.168925Z","iopub.status.idle":"2022-11-28T00:37:08.177810Z","shell.execute_reply.started":"2022-11-28T00:37:08.168886Z","shell.execute_reply":"2022-11-28T00:37:08.175813Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/spaceship-titanic/train.csv')\ntest_data = pd.read_csv('../input/spaceship-titanic/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-11-28T00:37:08.183912Z","iopub.execute_input":"2022-11-28T00:37:08.184597Z","iopub.status.idle":"2022-11-28T00:37:08.238588Z","shell.execute_reply.started":"2022-11-28T00:37:08.184538Z","shell.execute_reply":"2022-11-28T00:37:08.237222Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T00:37:08.240944Z","iopub.execute_input":"2022-11-28T00:37:08.241339Z","iopub.status.idle":"2022-11-28T00:37:08.269025Z","shell.execute_reply.started":"2022-11-28T00:37:08.241302Z","shell.execute_reply":"2022-11-28T00:37:08.267081Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n\n   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n\n   Transported  \n0        False  \n1         True  \n2        False  \n3        False  \n4         True  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>HomePlanet</th>\n      <th>CryoSleep</th>\n      <th>Cabin</th>\n      <th>Destination</th>\n      <th>Age</th>\n      <th>VIP</th>\n      <th>RoomService</th>\n      <th>FoodCourt</th>\n      <th>ShoppingMall</th>\n      <th>Spa</th>\n      <th>VRDeck</th>\n      <th>Name</th>\n      <th>Transported</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0001_01</td>\n      <td>Europa</td>\n      <td>False</td>\n      <td>B/0/P</td>\n      <td>TRAPPIST-1e</td>\n      <td>39.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Maham Ofracculy</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0002_01</td>\n      <td>Earth</td>\n      <td>False</td>\n      <td>F/0/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>24.0</td>\n      <td>False</td>\n      <td>109.0</td>\n      <td>9.0</td>\n      <td>25.0</td>\n      <td>549.0</td>\n      <td>44.0</td>\n      <td>Juanna Vines</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0003_01</td>\n      <td>Europa</td>\n      <td>False</td>\n      <td>A/0/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>58.0</td>\n      <td>True</td>\n      <td>43.0</td>\n      <td>3576.0</td>\n      <td>0.0</td>\n      <td>6715.0</td>\n      <td>49.0</td>\n      <td>Altark Susent</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0003_02</td>\n      <td>Europa</td>\n      <td>False</td>\n      <td>A/0/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>33.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1283.0</td>\n      <td>371.0</td>\n      <td>3329.0</td>\n      <td>193.0</td>\n      <td>Solam Susent</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0004_01</td>\n      <td>Earth</td>\n      <td>False</td>\n      <td>F/1/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>16.0</td>\n      <td>False</td>\n      <td>303.0</td>\n      <td>70.0</td>\n      <td>151.0</td>\n      <td>565.0</td>\n      <td>2.0</td>\n      <td>Willy Santantines</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_data.info()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T00:37:08.270744Z","iopub.execute_input":"2022-11-28T00:37:08.271753Z","iopub.status.idle":"2022-11-28T00:37:08.296167Z","shell.execute_reply.started":"2022-11-28T00:37:08.271680Z","shell.execute_reply":"2022-11-28T00:37:08.294820Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 8693 entries, 0 to 8692\nData columns (total 14 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   PassengerId   8693 non-null   object \n 1   HomePlanet    8492 non-null   object \n 2   CryoSleep     8476 non-null   object \n 3   Cabin         8494 non-null   object \n 4   Destination   8511 non-null   object \n 5   Age           8514 non-null   float64\n 6   VIP           8490 non-null   object \n 7   RoomService   8512 non-null   float64\n 8   FoodCourt     8510 non-null   float64\n 9   ShoppingMall  8485 non-null   float64\n 10  Spa           8510 non-null   float64\n 11  VRDeck        8505 non-null   float64\n 12  Name          8493 non-null   object \n 13  Transported   8693 non-null   bool   \ndtypes: bool(1), float64(6), object(7)\nmemory usage: 891.5+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data.describe()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T00:37:08.298761Z","iopub.execute_input":"2022-11-28T00:37:08.299962Z","iopub.status.idle":"2022-11-28T00:37:08.338386Z","shell.execute_reply.started":"2022-11-28T00:37:08.299910Z","shell.execute_reply":"2022-11-28T00:37:08.336797Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"               Age   RoomService     FoodCourt  ShoppingMall           Spa  \\\ncount  8514.000000   8512.000000   8510.000000   8485.000000   8510.000000   \nmean     28.827930    224.687617    458.077203    173.729169    311.138778   \nstd      14.489021    666.717663   1611.489240    604.696458   1136.705535   \nmin       0.000000      0.000000      0.000000      0.000000      0.000000   \n25%      19.000000      0.000000      0.000000      0.000000      0.000000   \n50%      27.000000      0.000000      0.000000      0.000000      0.000000   \n75%      38.000000     47.000000     76.000000     27.000000     59.000000   \nmax      79.000000  14327.000000  29813.000000  23492.000000  22408.000000   \n\n             VRDeck  \ncount   8505.000000  \nmean     304.854791  \nstd     1145.717189  \nmin        0.000000  \n25%        0.000000  \n50%        0.000000  \n75%       46.000000  \nmax    24133.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>RoomService</th>\n      <th>FoodCourt</th>\n      <th>ShoppingMall</th>\n      <th>Spa</th>\n      <th>VRDeck</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>8514.000000</td>\n      <td>8512.000000</td>\n      <td>8510.000000</td>\n      <td>8485.000000</td>\n      <td>8510.000000</td>\n      <td>8505.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>28.827930</td>\n      <td>224.687617</td>\n      <td>458.077203</td>\n      <td>173.729169</td>\n      <td>311.138778</td>\n      <td>304.854791</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>14.489021</td>\n      <td>666.717663</td>\n      <td>1611.489240</td>\n      <td>604.696458</td>\n      <td>1136.705535</td>\n      <td>1145.717189</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>19.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>27.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>38.000000</td>\n      <td>47.000000</td>\n      <td>76.000000</td>\n      <td>27.000000</td>\n      <td>59.000000</td>\n      <td>46.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>79.000000</td>\n      <td>14327.000000</td>\n      <td>29813.000000</td>\n      <td>23492.000000</td>\n      <td>22408.000000</td>\n      <td>24133.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Excluding what I consider true outliers\ntrain_data = train_data[(train_data['RoomService'] < 14000) | (pd.isna(train_data['RoomService']))]\ntrain_data = train_data[(train_data['ShoppingMall'] < 20000)| (pd.isna(train_data['ShoppingMall']))]\ntrain_data = train_data[(train_data['Spa'] < 20000)| (pd.isna(train_data['Spa']))]\ntrain_data = train_data[(train_data['VRDeck'] < 20000)| (pd.isna(train_data['VRDeck']))]\n#data\ntrain_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-11-28T00:37:08.339916Z","iopub.execute_input":"2022-11-28T00:37:08.340282Z","iopub.status.idle":"2022-11-28T00:37:08.363670Z","shell.execute_reply.started":"2022-11-28T00:37:08.340251Z","shell.execute_reply":"2022-11-28T00:37:08.362198Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"(8688, 14)"},"metadata":{}}]},{"cell_type":"code","source":"import seaborn as sns\nsns.heatmap(train_data.corr(), annot=True)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T00:37:08.367346Z","iopub.execute_input":"2022-11-28T00:37:08.368240Z","iopub.status.idle":"2022-11-28T00:37:08.977464Z","shell.execute_reply.started":"2022-11-28T00:37:08.368189Z","shell.execute_reply":"2022-11-28T00:37:08.975944Z"},"trusted":true},"execution_count":76,"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"train_data = train_data.set_index('PassengerId')\ntest_data = test_data.set_index('PassengerId')\ntrain_data['Transported'] = train_data['Transported'].map({True: 1, False: 0})                \ntrain_data.describe()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T00:37:08.979401Z","iopub.execute_input":"2022-11-28T00:37:08.979948Z","iopub.status.idle":"2022-11-28T00:37:09.031505Z","shell.execute_reply.started":"2022-11-28T00:37:08.979900Z","shell.execute_reply":"2022-11-28T00:37:09.030117Z"},"trusted":true},"execution_count":77,"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"               Age  RoomService     FoodCourt  ShoppingMall           Spa  \\\ncount  8509.000000  8507.000000   8505.000000   8480.000000   8506.000000   \nmean     28.821366   223.097332    455.763433    171.035731    308.535269   \nstd      14.483233   649.135976   1604.345238    549.297028   1111.425817   \nmin       0.000000     0.000000      0.000000      0.000000      0.000000   \n25%      19.000000     0.000000      0.000000      0.000000      0.000000   \n50%      27.000000     0.000000      0.000000      0.000000      0.000000   \n75%      38.000000    46.000000     76.000000     27.000000     59.000000   \nmax      79.000000  9920.000000  29813.000000  12253.000000  18572.000000   \n\n             VRDeck  Transported  \ncount   8500.000000  8688.000000  \nmean     299.800118     0.503798  \nstd     1095.155945     0.500014  \nmin        0.000000     0.000000  \n25%        0.000000     0.000000  \n50%        0.000000     1.000000  \n75%       46.000000     1.000000  \nmax    17306.000000     1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>RoomService</th>\n      <th>FoodCourt</th>\n      <th>ShoppingMall</th>\n      <th>Spa</th>\n      <th>VRDeck</th>\n      <th>Transported</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>8509.000000</td>\n      <td>8507.000000</td>\n      <td>8505.000000</td>\n      <td>8480.000000</td>\n      <td>8506.000000</td>\n      <td>8500.000000</td>\n      <td>8688.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>28.821366</td>\n      <td>223.097332</td>\n      <td>455.763433</td>\n      <td>171.035731</td>\n      <td>308.535269</td>\n      <td>299.800118</td>\n      <td>0.503798</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>14.483233</td>\n      <td>649.135976</td>\n      <td>1604.345238</td>\n      <td>549.297028</td>\n      <td>1111.425817</td>\n      <td>1095.155945</td>\n      <td>0.500014</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>19.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>27.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>38.000000</td>\n      <td>46.000000</td>\n      <td>76.000000</td>\n      <td>27.000000</td>\n      <td>59.000000</td>\n      <td>46.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>79.000000</td>\n      <td>9920.000000</td>\n      <td>29813.000000</td>\n      <td>12253.000000</td>\n      <td>18572.000000</td>\n      <td>17306.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# df with all data except name (ASSUMIING name has no impact on the output)\ndf =  train_data.drop(['Name'] , axis=1)\n# creating new columns from PassengerId and Cabin columns\n# new column group\ndf['Group'] = df.index.str[:4]\ndf['Group'] = df.Group.astype(int)\n# new column number in group\ndf['Number'] = df.index.str[-2:]\ndf['Number'] = df.Number.astype(int)\n# new column Deck\ndf['Deck'] = df.Cabin.str[0]\n# new column NumCabin\ndf['NumCabin'] = df.Cabin.str[2:-2]\n# new column Side\ndf['Side'] = df.Cabin.str[-1]\ndf = df.drop('Cabin', axis = 1)\n\n# SAME CHANGES FOR TEST\n# df with all data except name (ASSUMIING name has no impact on the output)\ntest_data =  test_data.drop(['Name'] , axis=1)\n# creating new columns from PassengerId and Cabin columns\n# new column group\ntest_data['Group'] = test_data.index.str[:4]\ntest_data['Group'] = test_data.Group.astype(int)\n# new column number in group\ntest_data['Number'] = test_data.index.str[-2:]\ntest_data['Number'] = test_data.Number.astype(int)\n# new column Deck\ntest_data['Deck'] = test_data.Cabin.str[0]\n# new column NumCabin\ntest_data['NumCabin'] = test_data.Cabin.str[2:-2]\n# new column Side\ntest_data['Side'] = test_data.Cabin.str[-1]\ntest_data = test_data.drop('Cabin', axis = 1)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-28T00:37:09.033326Z","iopub.execute_input":"2022-11-28T00:37:09.033713Z","iopub.status.idle":"2022-11-28T00:37:09.097806Z","shell.execute_reply.started":"2022-11-28T00:37:09.033679Z","shell.execute_reply":"2022-11-28T00:37:09.095793Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T00:37:09.100159Z","iopub.execute_input":"2022-11-28T00:37:09.100927Z","iopub.status.idle":"2022-11-28T00:37:09.115073Z","shell.execute_reply.started":"2022-11-28T00:37:09.100887Z","shell.execute_reply":"2022-11-28T00:37:09.113632Z"},"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"HomePlanet      201\nCryoSleep       217\nDestination     182\nAge             179\nVIP             203\nRoomService     181\nFoodCourt       183\nShoppingMall    208\nSpa             182\nVRDeck          188\nTransported       0\nGroup             0\nNumber            0\nDeck            198\nNumCabin        198\nSide            198\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"def fillnull(df):\n    notest = 'Transported' in df.columns\n    for i in range(len(df.columns)):\n        if(df.dtypes[i] == float):\n            if notest:\n                df[df.columns[i]] = df[df.columns[i]].fillna(df.groupby(['Group','Transported'])[df.columns[i]].transform('mean'))\n            df[df.columns[i]] = df[df.columns[i]].fillna(df.groupby(['Group'])[df.columns[i]].transform('mean'))\n            if notest:\n                df[df.columns[i]] = df[df.columns[i]].fillna(df.groupby(['Transported'])[df.columns[i]].transform('mean'))\n            df[df.columns[i]].fillna(df[df.columns[i]].mean(), inplace=True)\n        else:\n            #I need to figure out how to replace null values with the mode of their groups in cathegorical columns as i do with\n            #the mean in numeric columns\n            if notest:\n                df.dropna(inplace = True)\n            else:\n                df[df.columns[i]] = df[df.columns[i]].fillna(df[df.columns[i]].mode()[0])\n    print(df.isnull().sum())\n\nfillnull(df)\nfillnull(test_data)\n\ndf['CryoSleep'] = df['CryoSleep'] ==True\ndf['VIP'] = df['VIP'] ==True","metadata":{"execution":{"iopub.status.busy":"2022-11-28T00:37:09.120756Z","iopub.execute_input":"2022-11-28T00:37:09.121831Z","iopub.status.idle":"2022-11-28T00:37:09.273970Z","shell.execute_reply.started":"2022-11-28T00:37:09.121781Z","shell.execute_reply":"2022-11-28T00:37:09.272985Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"HomePlanet      0\nCryoSleep       0\nDestination     0\nAge             0\nVIP             0\nRoomService     0\nFoodCourt       0\nShoppingMall    0\nSpa             0\nVRDeck          0\nTransported     0\nGroup           0\nNumber          0\nDeck            0\nNumCabin        0\nSide            0\ndtype: int64\nHomePlanet      0\nCryoSleep       0\nDestination     0\nAge             0\nVIP             0\nRoomService     0\nFoodCourt       0\nShoppingMall    0\nSpa             0\nVRDeck          0\nGroup           0\nNumber          0\nDeck            0\nNumCabin        0\nSide            0\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"df['NumCabin'] = df.NumCabin.astype(int)\ntest_data['NumCabin'] = test_data.NumCabin.astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T00:37:09.275151Z","iopub.execute_input":"2022-11-28T00:37:09.276299Z","iopub.status.idle":"2022-11-28T00:37:09.286468Z","shell.execute_reply.started":"2022-11-28T00:37:09.276254Z","shell.execute_reply":"2022-11-28T00:37:09.284699Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"target = df['Transported']\ndf =  df.drop(['Transported'] , axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T00:37:09.288140Z","iopub.execute_input":"2022-11-28T00:37:09.288491Z","iopub.status.idle":"2022-11-28T00:37:09.302880Z","shell.execute_reply.started":"2022-11-28T00:37:09.288460Z","shell.execute_reply":"2022-11-28T00:37:09.301581Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"features_num = []\nfeatures_cat = []\n\nfor i in range(len(df.dtypes)):\n    if df.dtypes[i] == 'object':\n        features_cat.append(df.columns[i])\n    else:\n        features_num.append(df.columns[i])\n        \ntransformer_num = make_pipeline(\n    SimpleImputer(strategy=\"constant\"), # there are a few missing values\n    StandardScaler(),\n)\ntransformer_cat = make_pipeline(\n    SimpleImputer(strategy=\"constant\", fill_value=\"NA\"),\n    OneHotEncoder(handle_unknown='ignore'),\n)\n\npreprocessor = make_column_transformer(\n    (transformer_num, features_num),\n    (transformer_cat, features_cat),\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T00:37:09.304474Z","iopub.execute_input":"2022-11-28T00:37:09.304922Z","iopub.status.idle":"2022-11-28T00:37:09.316429Z","shell.execute_reply.started":"2022-11-28T00:37:09.304879Z","shell.execute_reply":"2022-11-28T00:37:09.315295Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"# stratify - make sure classes are evenlly represented across splits\nX_train, X_valid, y_train, y_valid = \\\n    train_test_split(df, target, stratify=target, train_size=0.75)\n\nX_train = preprocessor.fit_transform(X_train)\nX_valid = preprocessor.transform(X_valid)\n\ninput_shape = [X_train.shape[1]]","metadata":{"execution":{"iopub.status.busy":"2022-11-28T00:37:09.317915Z","iopub.execute_input":"2022-11-28T00:37:09.319294Z","iopub.status.idle":"2022-11-28T00:37:09.389635Z","shell.execute_reply.started":"2022-11-28T00:37:09.319208Z","shell.execute_reply":"2022-11-28T00:37:09.387951Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\nmodels = []\nmodel =  keras.Sequential([\n    layers.BatchNormalization(input_shape=input_shape),\n    layers.Dense(256, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(256, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(1, activation='sigmoid'),\n])\nmodels.append(model)\nmodel =  keras.Sequential([\n    layers.BatchNormalization(input_shape=input_shape),\n    layers.Dense(256, activation='selu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(64, activation='elu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(1, activation='sigmoid'),\n])\nmodels.append(model)\nmodel =  keras.Sequential([\n    layers.BatchNormalization(input_shape=input_shape),\n    layers.Dense(64, activation='selu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(256, activation= keras.layers.LeakyReLU(alpha=0.1)),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(512, activation='selu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(1, activation='sigmoid'),\n])\nmodels.append(model)\nmodel =  keras.Sequential([\n    layers.BatchNormalization(input_shape=input_shape),\n    layers.Dense(64, activation='selu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(256, activation= keras.layers.LeakyReLU(alpha=0.1)),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(64, activation='elu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(1, activation='sigmoid'),\n])\nmodels.append(model)\nmodel =  keras.Sequential([\n    layers.BatchNormalization(input_shape=input_shape),\n    layers.Dense(64, activation='selu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(256, activation=keras.layers.PReLU()),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(64, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(1, activation='sigmoid'),\n])\nmodels.append(model)\n\nmodel =  keras.Sequential([\n    layers.BatchNormalization(input_shape=input_shape),\n    layers.Dense(128, activation='selu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(128, activation=keras.layers.PReLU()),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n     layers.Dense(128, activation= keras.layers.LeakyReLU(alpha=0.1)),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(128, activation='elu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(1, activation='sigmoid'),\n])\nmodels.append(model)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-28T00:37:09.392127Z","iopub.execute_input":"2022-11-28T00:37:09.392830Z","iopub.status.idle":"2022-11-28T00:37:10.003673Z","shell.execute_reply.started":"2022-11-28T00:37:09.392788Z","shell.execute_reply":"2022-11-28T00:37:10.002312Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"for model in models:\n    model.compile(\n        optimizer='adam',\n        loss='binary_crossentropy',\n        metrics=['binary_accuracy'],\n    )\nearly_stopping = keras.callbacks.EarlyStopping(\n    patience=20,\n    min_delta=0.001,\n    restore_best_weights=True,\n)\n\nhistories = []\nfor model in models:\n    history = model.fit(\n        X_train, y_train,\n        validation_data=(X_valid, y_valid),\n        batch_size=256,\n        epochs=200,\n\n        callbacks=[early_stopping],\n    )\n    histories.append(history)\n","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-11-28T00:37:10.005251Z","iopub.execute_input":"2022-11-28T00:37:10.005712Z","iopub.status.idle":"2022-11-28T00:40:36.811345Z","shell.execute_reply.started":"2022-11-28T00:37:10.005664Z","shell.execute_reply":"2022-11-28T00:40:36.810064Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"Epoch 1/200\n20/20 [==============================] - 3s 26ms/step - loss: 0.6145 - binary_accuracy: 0.7178 - val_loss: 0.5631 - val_binary_accuracy: 0.7363\nEpoch 2/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.4823 - binary_accuracy: 0.7777 - val_loss: 0.5516 - val_binary_accuracy: 0.6913\nEpoch 3/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.4574 - binary_accuracy: 0.7775 - val_loss: 0.5420 - val_binary_accuracy: 0.6753\nEpoch 4/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4447 - binary_accuracy: 0.7915 - val_loss: 0.5389 - val_binary_accuracy: 0.6688\nEpoch 5/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4296 - binary_accuracy: 0.7949 - val_loss: 0.5220 - val_binary_accuracy: 0.6818\nEpoch 6/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4213 - binary_accuracy: 0.7949 - val_loss: 0.5093 - val_binary_accuracy: 0.7025\nEpoch 7/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4154 - binary_accuracy: 0.8004 - val_loss: 0.4909 - val_binary_accuracy: 0.7368\nEpoch 8/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.4073 - binary_accuracy: 0.8022 - val_loss: 0.4810 - val_binary_accuracy: 0.7410\nEpoch 9/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4045 - binary_accuracy: 0.8020 - val_loss: 0.4609 - val_binary_accuracy: 0.7611\nEpoch 10/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.4029 - binary_accuracy: 0.8059 - val_loss: 0.4418 - val_binary_accuracy: 0.7853\nEpoch 11/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3942 - binary_accuracy: 0.8132 - val_loss: 0.4270 - val_binary_accuracy: 0.7901\nEpoch 12/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3962 - binary_accuracy: 0.8069 - val_loss: 0.4271 - val_binary_accuracy: 0.7812\nEpoch 13/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4030 - binary_accuracy: 0.8063 - val_loss: 0.4121 - val_binary_accuracy: 0.7983\nEpoch 14/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3945 - binary_accuracy: 0.8087 - val_loss: 0.4107 - val_binary_accuracy: 0.7983\nEpoch 15/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3865 - binary_accuracy: 0.8158 - val_loss: 0.4011 - val_binary_accuracy: 0.8054\nEpoch 16/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3856 - binary_accuracy: 0.8203 - val_loss: 0.4027 - val_binary_accuracy: 0.8048\nEpoch 17/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3765 - binary_accuracy: 0.8209 - val_loss: 0.3975 - val_binary_accuracy: 0.8108\nEpoch 18/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3822 - binary_accuracy: 0.8160 - val_loss: 0.3961 - val_binary_accuracy: 0.8066\nEpoch 19/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3944 - binary_accuracy: 0.8087 - val_loss: 0.3917 - val_binary_accuracy: 0.8090\nEpoch 20/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3791 - binary_accuracy: 0.8172 - val_loss: 0.3918 - val_binary_accuracy: 0.8119\nEpoch 21/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3724 - binary_accuracy: 0.8243 - val_loss: 0.3914 - val_binary_accuracy: 0.8108\nEpoch 22/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3751 - binary_accuracy: 0.8197 - val_loss: 0.3930 - val_binary_accuracy: 0.8007\nEpoch 23/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3711 - binary_accuracy: 0.8211 - val_loss: 0.3910 - val_binary_accuracy: 0.8078\nEpoch 24/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3745 - binary_accuracy: 0.8178 - val_loss: 0.3910 - val_binary_accuracy: 0.8066\nEpoch 25/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3670 - binary_accuracy: 0.8203 - val_loss: 0.3876 - val_binary_accuracy: 0.8149\nEpoch 26/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3725 - binary_accuracy: 0.8191 - val_loss: 0.3864 - val_binary_accuracy: 0.8060\nEpoch 27/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3665 - binary_accuracy: 0.8213 - val_loss: 0.3870 - val_binary_accuracy: 0.8060\nEpoch 28/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3614 - binary_accuracy: 0.8321 - val_loss: 0.3892 - val_binary_accuracy: 0.8078\nEpoch 29/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3624 - binary_accuracy: 0.8260 - val_loss: 0.3881 - val_binary_accuracy: 0.8072\nEpoch 30/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3650 - binary_accuracy: 0.8258 - val_loss: 0.3859 - val_binary_accuracy: 0.8072\nEpoch 31/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3661 - binary_accuracy: 0.8280 - val_loss: 0.3865 - val_binary_accuracy: 0.8090\nEpoch 32/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3597 - binary_accuracy: 0.8272 - val_loss: 0.3865 - val_binary_accuracy: 0.8084\nEpoch 33/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3588 - binary_accuracy: 0.8215 - val_loss: 0.3886 - val_binary_accuracy: 0.8108\nEpoch 34/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3645 - binary_accuracy: 0.8241 - val_loss: 0.3886 - val_binary_accuracy: 0.8060\nEpoch 35/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3536 - binary_accuracy: 0.8314 - val_loss: 0.3856 - val_binary_accuracy: 0.8031\nEpoch 36/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3522 - binary_accuracy: 0.8345 - val_loss: 0.3864 - val_binary_accuracy: 0.8084\nEpoch 37/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3529 - binary_accuracy: 0.8335 - val_loss: 0.3902 - val_binary_accuracy: 0.8043\nEpoch 38/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3527 - binary_accuracy: 0.8321 - val_loss: 0.3907 - val_binary_accuracy: 0.8013\nEpoch 39/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3619 - binary_accuracy: 0.8262 - val_loss: 0.3886 - val_binary_accuracy: 0.8108\nEpoch 40/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3572 - binary_accuracy: 0.8288 - val_loss: 0.3859 - val_binary_accuracy: 0.8090\nEpoch 41/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3476 - binary_accuracy: 0.8302 - val_loss: 0.3866 - val_binary_accuracy: 0.8066\nEpoch 42/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3485 - binary_accuracy: 0.8367 - val_loss: 0.3896 - val_binary_accuracy: 0.8090\nEpoch 43/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3472 - binary_accuracy: 0.8339 - val_loss: 0.3897 - val_binary_accuracy: 0.8119\nEpoch 44/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3447 - binary_accuracy: 0.8331 - val_loss: 0.3873 - val_binary_accuracy: 0.8060\nEpoch 45/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3416 - binary_accuracy: 0.8426 - val_loss: 0.3877 - val_binary_accuracy: 0.8037\nEpoch 46/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3483 - binary_accuracy: 0.8333 - val_loss: 0.3861 - val_binary_accuracy: 0.8084\nEpoch 1/200\n20/20 [==============================] - 2s 25ms/step - loss: 0.5859 - binary_accuracy: 0.7158 - val_loss: 0.4705 - val_binary_accuracy: 0.7907\nEpoch 2/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.4881 - binary_accuracy: 0.7692 - val_loss: 0.4518 - val_binary_accuracy: 0.8054\nEpoch 3/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.4687 - binary_accuracy: 0.7714 - val_loss: 0.4440 - val_binary_accuracy: 0.8007\nEpoch 4/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.4495 - binary_accuracy: 0.7888 - val_loss: 0.4377 - val_binary_accuracy: 0.7983\nEpoch 5/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.4449 - binary_accuracy: 0.7868 - val_loss: 0.4343 - val_binary_accuracy: 0.8031\nEpoch 6/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.4405 - binary_accuracy: 0.7880 - val_loss: 0.4278 - val_binary_accuracy: 0.7978\nEpoch 7/200\n20/20 [==============================] - 0s 9ms/step - loss: 0.4365 - binary_accuracy: 0.7888 - val_loss: 0.4266 - val_binary_accuracy: 0.7995\nEpoch 8/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.4315 - binary_accuracy: 0.7915 - val_loss: 0.4236 - val_binary_accuracy: 0.8048\nEpoch 9/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.4288 - binary_accuracy: 0.7978 - val_loss: 0.4204 - val_binary_accuracy: 0.8084\nEpoch 10/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.4253 - binary_accuracy: 0.7892 - val_loss: 0.4186 - val_binary_accuracy: 0.8084\nEpoch 11/200\n20/20 [==============================] - 0s 9ms/step - loss: 0.4276 - binary_accuracy: 0.7921 - val_loss: 0.4164 - val_binary_accuracy: 0.8072\nEpoch 12/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.4209 - binary_accuracy: 0.7998 - val_loss: 0.4157 - val_binary_accuracy: 0.8013\nEpoch 13/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.4256 - binary_accuracy: 0.7933 - val_loss: 0.4144 - val_binary_accuracy: 0.8007\nEpoch 14/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.4171 - binary_accuracy: 0.7963 - val_loss: 0.4122 - val_binary_accuracy: 0.8007\nEpoch 15/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.4146 - binary_accuracy: 0.7963 - val_loss: 0.4110 - val_binary_accuracy: 0.8048\nEpoch 16/200\n20/20 [==============================] - 0s 9ms/step - loss: 0.4191 - binary_accuracy: 0.7984 - val_loss: 0.4112 - val_binary_accuracy: 0.8019\nEpoch 17/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.4128 - binary_accuracy: 0.7988 - val_loss: 0.4090 - val_binary_accuracy: 0.8013\nEpoch 18/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.4086 - binary_accuracy: 0.7990 - val_loss: 0.4097 - val_binary_accuracy: 0.8007\nEpoch 19/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.4065 - binary_accuracy: 0.8000 - val_loss: 0.4111 - val_binary_accuracy: 0.8037\nEpoch 20/200\n20/20 [==============================] - 0s 9ms/step - loss: 0.4119 - binary_accuracy: 0.7988 - val_loss: 0.4096 - val_binary_accuracy: 0.7995\nEpoch 21/200\n20/20 [==============================] - 0s 9ms/step - loss: 0.4070 - binary_accuracy: 0.7996 - val_loss: 0.4099 - val_binary_accuracy: 0.7972\nEpoch 22/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.4041 - binary_accuracy: 0.8079 - val_loss: 0.4085 - val_binary_accuracy: 0.8066\nEpoch 23/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.4035 - binary_accuracy: 0.8055 - val_loss: 0.4074 - val_binary_accuracy: 0.7978\nEpoch 24/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.4009 - binary_accuracy: 0.8067 - val_loss: 0.4090 - val_binary_accuracy: 0.8007\nEpoch 25/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.4038 - binary_accuracy: 0.8037 - val_loss: 0.4096 - val_binary_accuracy: 0.8031\nEpoch 26/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3987 - binary_accuracy: 0.8059 - val_loss: 0.4085 - val_binary_accuracy: 0.8007\nEpoch 27/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.4045 - binary_accuracy: 0.8085 - val_loss: 0.4063 - val_binary_accuracy: 0.8025\nEpoch 28/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.4041 - binary_accuracy: 0.8049 - val_loss: 0.4080 - val_binary_accuracy: 0.8019\nEpoch 29/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3999 - binary_accuracy: 0.8039 - val_loss: 0.4088 - val_binary_accuracy: 0.8060\nEpoch 30/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.4016 - binary_accuracy: 0.8073 - val_loss: 0.4067 - val_binary_accuracy: 0.8001\nEpoch 31/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.4023 - binary_accuracy: 0.8061 - val_loss: 0.4080 - val_binary_accuracy: 0.7978\nEpoch 32/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.4010 - binary_accuracy: 0.8095 - val_loss: 0.4061 - val_binary_accuracy: 0.8025\nEpoch 33/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3963 - binary_accuracy: 0.8128 - val_loss: 0.4057 - val_binary_accuracy: 0.8037\nEpoch 34/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3958 - binary_accuracy: 0.8091 - val_loss: 0.4046 - val_binary_accuracy: 0.8001\nEpoch 35/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3955 - binary_accuracy: 0.8142 - val_loss: 0.4046 - val_binary_accuracy: 0.8025\nEpoch 36/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3982 - binary_accuracy: 0.8053 - val_loss: 0.4034 - val_binary_accuracy: 0.8043\nEpoch 37/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3999 - binary_accuracy: 0.8075 - val_loss: 0.4043 - val_binary_accuracy: 0.8031\nEpoch 38/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3965 - binary_accuracy: 0.8039 - val_loss: 0.4041 - val_binary_accuracy: 0.8037\nEpoch 39/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.4045 - binary_accuracy: 0.8085 - val_loss: 0.4059 - val_binary_accuracy: 0.8013\nEpoch 40/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3983 - binary_accuracy: 0.8083 - val_loss: 0.4040 - val_binary_accuracy: 0.7989\nEpoch 41/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3947 - binary_accuracy: 0.8093 - val_loss: 0.4033 - val_binary_accuracy: 0.8007\nEpoch 42/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3976 - binary_accuracy: 0.8105 - val_loss: 0.4030 - val_binary_accuracy: 0.8001\nEpoch 43/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3983 - binary_accuracy: 0.8105 - val_loss: 0.4045 - val_binary_accuracy: 0.8013\nEpoch 44/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3932 - binary_accuracy: 0.8087 - val_loss: 0.4031 - val_binary_accuracy: 0.8013\nEpoch 45/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3922 - binary_accuracy: 0.8152 - val_loss: 0.4039 - val_binary_accuracy: 0.8048\nEpoch 46/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3892 - binary_accuracy: 0.8124 - val_loss: 0.4028 - val_binary_accuracy: 0.8037\nEpoch 47/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3894 - binary_accuracy: 0.8132 - val_loss: 0.4011 - val_binary_accuracy: 0.8043\nEpoch 48/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3910 - binary_accuracy: 0.8087 - val_loss: 0.4038 - val_binary_accuracy: 0.8031\nEpoch 49/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3931 - binary_accuracy: 0.8063 - val_loss: 0.4022 - val_binary_accuracy: 0.8031\nEpoch 50/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3903 - binary_accuracy: 0.8134 - val_loss: 0.4014 - val_binary_accuracy: 0.7995\nEpoch 51/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3886 - binary_accuracy: 0.8162 - val_loss: 0.4002 - val_binary_accuracy: 0.8007\nEpoch 52/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3935 - binary_accuracy: 0.8152 - val_loss: 0.4005 - val_binary_accuracy: 0.8025\nEpoch 53/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3947 - binary_accuracy: 0.8097 - val_loss: 0.3993 - val_binary_accuracy: 0.8031\nEpoch 54/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3877 - binary_accuracy: 0.8099 - val_loss: 0.4008 - val_binary_accuracy: 0.8025\nEpoch 55/200\n20/20 [==============================] - 0s 9ms/step - loss: 0.3989 - binary_accuracy: 0.8053 - val_loss: 0.3991 - val_binary_accuracy: 0.8025\nEpoch 56/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3892 - binary_accuracy: 0.8091 - val_loss: 0.3990 - val_binary_accuracy: 0.8048\nEpoch 57/200\n20/20 [==============================] - 0s 9ms/step - loss: 0.3901 - binary_accuracy: 0.8081 - val_loss: 0.4015 - val_binary_accuracy: 0.8013\nEpoch 58/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3894 - binary_accuracy: 0.8118 - val_loss: 0.3997 - val_binary_accuracy: 0.8031\nEpoch 59/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3843 - binary_accuracy: 0.8146 - val_loss: 0.4027 - val_binary_accuracy: 0.8037\nEpoch 60/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3941 - binary_accuracy: 0.8132 - val_loss: 0.3991 - val_binary_accuracy: 0.8031\nEpoch 61/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3910 - binary_accuracy: 0.8105 - val_loss: 0.3987 - val_binary_accuracy: 0.8043\nEpoch 62/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3904 - binary_accuracy: 0.8136 - val_loss: 0.3988 - val_binary_accuracy: 0.8019\nEpoch 63/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3851 - binary_accuracy: 0.8140 - val_loss: 0.3999 - val_binary_accuracy: 0.8019\nEpoch 64/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3870 - binary_accuracy: 0.8136 - val_loss: 0.3998 - val_binary_accuracy: 0.8054\nEpoch 65/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3927 - binary_accuracy: 0.8089 - val_loss: 0.3992 - val_binary_accuracy: 0.8072\nEpoch 66/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3879 - binary_accuracy: 0.8099 - val_loss: 0.3981 - val_binary_accuracy: 0.8078\nEpoch 67/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3942 - binary_accuracy: 0.8073 - val_loss: 0.3976 - val_binary_accuracy: 0.8037\nEpoch 68/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3875 - binary_accuracy: 0.8107 - val_loss: 0.3978 - val_binary_accuracy: 0.8078\nEpoch 69/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3918 - binary_accuracy: 0.8112 - val_loss: 0.4001 - val_binary_accuracy: 0.7989\nEpoch 70/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3890 - binary_accuracy: 0.8116 - val_loss: 0.3978 - val_binary_accuracy: 0.8072\nEpoch 71/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3905 - binary_accuracy: 0.8083 - val_loss: 0.3972 - val_binary_accuracy: 0.8072\nEpoch 72/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3871 - binary_accuracy: 0.8136 - val_loss: 0.3982 - val_binary_accuracy: 0.8066\nEpoch 73/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3905 - binary_accuracy: 0.8126 - val_loss: 0.3994 - val_binary_accuracy: 0.8037\nEpoch 74/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3893 - binary_accuracy: 0.8099 - val_loss: 0.3956 - val_binary_accuracy: 0.8060\nEpoch 75/200\n20/20 [==============================] - 0s 9ms/step - loss: 0.3837 - binary_accuracy: 0.8136 - val_loss: 0.3956 - val_binary_accuracy: 0.8060\nEpoch 76/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3891 - binary_accuracy: 0.8154 - val_loss: 0.3964 - val_binary_accuracy: 0.8048\nEpoch 77/200\n20/20 [==============================] - 0s 9ms/step - loss: 0.3875 - binary_accuracy: 0.8146 - val_loss: 0.3976 - val_binary_accuracy: 0.8031\nEpoch 78/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3861 - binary_accuracy: 0.8152 - val_loss: 0.3978 - val_binary_accuracy: 0.8031\nEpoch 79/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3876 - binary_accuracy: 0.8130 - val_loss: 0.3996 - val_binary_accuracy: 0.8007\nEpoch 80/200\n20/20 [==============================] - 0s 9ms/step - loss: 0.3862 - binary_accuracy: 0.8162 - val_loss: 0.4001 - val_binary_accuracy: 0.8037\nEpoch 81/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3841 - binary_accuracy: 0.8174 - val_loss: 0.3994 - val_binary_accuracy: 0.8054\nEpoch 82/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3837 - binary_accuracy: 0.8176 - val_loss: 0.3989 - val_binary_accuracy: 0.8037\nEpoch 83/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3819 - binary_accuracy: 0.8120 - val_loss: 0.3961 - val_binary_accuracy: 0.8037\nEpoch 84/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3808 - binary_accuracy: 0.8134 - val_loss: 0.3985 - val_binary_accuracy: 0.8019\nEpoch 85/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3858 - binary_accuracy: 0.8172 - val_loss: 0.3974 - val_binary_accuracy: 0.8060\nEpoch 86/200\n20/20 [==============================] - 0s 9ms/step - loss: 0.3826 - binary_accuracy: 0.8130 - val_loss: 0.3983 - val_binary_accuracy: 0.8013\nEpoch 87/200\n20/20 [==============================] - 0s 9ms/step - loss: 0.3811 - binary_accuracy: 0.8183 - val_loss: 0.3949 - val_binary_accuracy: 0.8066\nEpoch 88/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3830 - binary_accuracy: 0.8166 - val_loss: 0.3972 - val_binary_accuracy: 0.8031\nEpoch 89/200\n20/20 [==============================] - 0s 9ms/step - loss: 0.3890 - binary_accuracy: 0.8079 - val_loss: 0.3947 - val_binary_accuracy: 0.8072\nEpoch 90/200\n20/20 [==============================] - 0s 9ms/step - loss: 0.3838 - binary_accuracy: 0.8154 - val_loss: 0.3943 - val_binary_accuracy: 0.8019\nEpoch 91/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3834 - binary_accuracy: 0.8170 - val_loss: 0.3949 - val_binary_accuracy: 0.7995\nEpoch 92/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3814 - binary_accuracy: 0.8114 - val_loss: 0.3970 - val_binary_accuracy: 0.8043\nEpoch 93/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3829 - binary_accuracy: 0.8183 - val_loss: 0.3974 - val_binary_accuracy: 0.8048\nEpoch 94/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3835 - binary_accuracy: 0.8097 - val_loss: 0.3951 - val_binary_accuracy: 0.8031\nEpoch 95/200\n20/20 [==============================] - 0s 9ms/step - loss: 0.3797 - binary_accuracy: 0.8237 - val_loss: 0.3968 - val_binary_accuracy: 0.8013\nEpoch 96/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3819 - binary_accuracy: 0.8160 - val_loss: 0.3974 - val_binary_accuracy: 0.8031\nEpoch 97/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3816 - binary_accuracy: 0.8199 - val_loss: 0.3953 - val_binary_accuracy: 0.8025\nEpoch 98/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3742 - binary_accuracy: 0.8156 - val_loss: 0.3941 - val_binary_accuracy: 0.8037\nEpoch 99/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3840 - binary_accuracy: 0.8112 - val_loss: 0.3953 - val_binary_accuracy: 0.8031\nEpoch 100/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3776 - binary_accuracy: 0.8178 - val_loss: 0.3950 - val_binary_accuracy: 0.8013\nEpoch 101/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3773 - binary_accuracy: 0.8207 - val_loss: 0.3945 - val_binary_accuracy: 0.8048\nEpoch 102/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3788 - binary_accuracy: 0.8195 - val_loss: 0.3952 - val_binary_accuracy: 0.8048\nEpoch 103/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3765 - binary_accuracy: 0.8174 - val_loss: 0.3958 - val_binary_accuracy: 0.8043\nEpoch 104/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3785 - binary_accuracy: 0.8172 - val_loss: 0.3945 - val_binary_accuracy: 0.8025\nEpoch 105/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3772 - binary_accuracy: 0.8211 - val_loss: 0.3964 - val_binary_accuracy: 0.8043\nEpoch 106/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3756 - binary_accuracy: 0.8181 - val_loss: 0.3950 - val_binary_accuracy: 0.8025\nEpoch 107/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3774 - binary_accuracy: 0.8205 - val_loss: 0.3947 - val_binary_accuracy: 0.8054\nEpoch 108/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3804 - binary_accuracy: 0.8154 - val_loss: 0.3923 - val_binary_accuracy: 0.8096\nEpoch 109/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3783 - binary_accuracy: 0.8160 - val_loss: 0.3923 - val_binary_accuracy: 0.8048\nEpoch 110/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3799 - binary_accuracy: 0.8179 - val_loss: 0.3931 - val_binary_accuracy: 0.8025\nEpoch 111/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3793 - binary_accuracy: 0.8146 - val_loss: 0.3934 - val_binary_accuracy: 0.8043\nEpoch 112/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3767 - binary_accuracy: 0.8191 - val_loss: 0.3933 - val_binary_accuracy: 0.8048\nEpoch 113/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3829 - binary_accuracy: 0.8132 - val_loss: 0.3912 - val_binary_accuracy: 0.8072\nEpoch 114/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3819 - binary_accuracy: 0.8130 - val_loss: 0.3923 - val_binary_accuracy: 0.8060\nEpoch 115/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3787 - binary_accuracy: 0.8176 - val_loss: 0.3924 - val_binary_accuracy: 0.8037\nEpoch 116/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3788 - binary_accuracy: 0.8187 - val_loss: 0.3918 - val_binary_accuracy: 0.8048\nEpoch 117/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3775 - binary_accuracy: 0.8140 - val_loss: 0.3925 - val_binary_accuracy: 0.8013\nEpoch 118/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3845 - binary_accuracy: 0.8112 - val_loss: 0.3918 - val_binary_accuracy: 0.8037\nEpoch 119/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3772 - binary_accuracy: 0.8172 - val_loss: 0.3904 - val_binary_accuracy: 0.8084\nEpoch 120/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3769 - binary_accuracy: 0.8166 - val_loss: 0.3928 - val_binary_accuracy: 0.8054\nEpoch 121/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3711 - binary_accuracy: 0.8229 - val_loss: 0.3931 - val_binary_accuracy: 0.8054\nEpoch 122/200\n20/20 [==============================] - 0s 9ms/step - loss: 0.3775 - binary_accuracy: 0.8185 - val_loss: 0.3938 - val_binary_accuracy: 0.8060\nEpoch 123/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3769 - binary_accuracy: 0.8187 - val_loss: 0.3907 - val_binary_accuracy: 0.8114\nEpoch 124/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3785 - binary_accuracy: 0.8183 - val_loss: 0.3925 - val_binary_accuracy: 0.8060\nEpoch 125/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3726 - binary_accuracy: 0.8227 - val_loss: 0.3913 - val_binary_accuracy: 0.8066\nEpoch 126/200\n20/20 [==============================] - 0s 9ms/step - loss: 0.3804 - binary_accuracy: 0.8156 - val_loss: 0.3942 - val_binary_accuracy: 0.8001\nEpoch 127/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3714 - binary_accuracy: 0.8229 - val_loss: 0.3916 - val_binary_accuracy: 0.8066\nEpoch 128/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3730 - binary_accuracy: 0.8213 - val_loss: 0.3903 - val_binary_accuracy: 0.8048\nEpoch 129/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3744 - binary_accuracy: 0.8172 - val_loss: 0.3919 - val_binary_accuracy: 0.8037\nEpoch 130/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3822 - binary_accuracy: 0.8179 - val_loss: 0.3951 - val_binary_accuracy: 0.8031\nEpoch 131/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3743 - binary_accuracy: 0.8209 - val_loss: 0.3919 - val_binary_accuracy: 0.8048\nEpoch 132/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3735 - binary_accuracy: 0.8176 - val_loss: 0.3920 - val_binary_accuracy: 0.8048\nEpoch 133/200\n20/20 [==============================] - 0s 10ms/step - loss: 0.3769 - binary_accuracy: 0.8213 - val_loss: 0.3929 - val_binary_accuracy: 0.8066\nEpoch 1/200\n20/20 [==============================] - 2s 34ms/step - loss: 0.6456 - binary_accuracy: 0.7116 - val_loss: 0.4873 - val_binary_accuracy: 0.7771\nEpoch 2/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.5516 - binary_accuracy: 0.7333 - val_loss: 0.4750 - val_binary_accuracy: 0.7983\nEpoch 3/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.5352 - binary_accuracy: 0.7327 - val_loss: 0.4540 - val_binary_accuracy: 0.8001\nEpoch 4/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.5092 - binary_accuracy: 0.7473 - val_loss: 0.4444 - val_binary_accuracy: 0.8031\nEpoch 5/200\n20/20 [==============================] - 0s 18ms/step - loss: 0.4948 - binary_accuracy: 0.7613 - val_loss: 0.4358 - val_binary_accuracy: 0.7995\nEpoch 6/200\n20/20 [==============================] - 0s 18ms/step - loss: 0.4905 - binary_accuracy: 0.7639 - val_loss: 0.4321 - val_binary_accuracy: 0.7960\nEpoch 7/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.4847 - binary_accuracy: 0.7694 - val_loss: 0.4264 - val_binary_accuracy: 0.7972\nEpoch 8/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.4631 - binary_accuracy: 0.7728 - val_loss: 0.4207 - val_binary_accuracy: 0.8084\nEpoch 9/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.4637 - binary_accuracy: 0.7771 - val_loss: 0.4199 - val_binary_accuracy: 0.8078\nEpoch 10/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.4674 - binary_accuracy: 0.7688 - val_loss: 0.4162 - val_binary_accuracy: 0.7924\nEpoch 11/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.4509 - binary_accuracy: 0.7897 - val_loss: 0.4142 - val_binary_accuracy: 0.7948\nEpoch 12/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.4408 - binary_accuracy: 0.7868 - val_loss: 0.4111 - val_binary_accuracy: 0.8019\nEpoch 13/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.4444 - binary_accuracy: 0.7822 - val_loss: 0.4181 - val_binary_accuracy: 0.8054\nEpoch 14/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.4334 - binary_accuracy: 0.7874 - val_loss: 0.4168 - val_binary_accuracy: 0.8037\nEpoch 15/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.4276 - binary_accuracy: 0.7966 - val_loss: 0.4170 - val_binary_accuracy: 0.8001\nEpoch 16/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.4280 - binary_accuracy: 0.7937 - val_loss: 0.4052 - val_binary_accuracy: 0.8060\nEpoch 17/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.4277 - binary_accuracy: 0.7943 - val_loss: 0.4115 - val_binary_accuracy: 0.8043\nEpoch 18/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.4314 - binary_accuracy: 0.7939 - val_loss: 0.4073 - val_binary_accuracy: 0.8037\nEpoch 19/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.4237 - binary_accuracy: 0.7892 - val_loss: 0.4069 - val_binary_accuracy: 0.8048\nEpoch 20/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.4170 - binary_accuracy: 0.7998 - val_loss: 0.4109 - val_binary_accuracy: 0.7995\nEpoch 21/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.4144 - binary_accuracy: 0.7994 - val_loss: 0.4138 - val_binary_accuracy: 0.8007\nEpoch 22/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.4179 - binary_accuracy: 0.8000 - val_loss: 0.4111 - val_binary_accuracy: 0.7983\nEpoch 23/200\n20/20 [==============================] - 1s 29ms/step - loss: 0.4225 - binary_accuracy: 0.7961 - val_loss: 0.4101 - val_binary_accuracy: 0.8066\nEpoch 24/200\n20/20 [==============================] - 1s 43ms/step - loss: 0.4185 - binary_accuracy: 0.7955 - val_loss: 0.4120 - val_binary_accuracy: 0.7972\nEpoch 25/200\n20/20 [==============================] - 0s 23ms/step - loss: 0.4225 - binary_accuracy: 0.7892 - val_loss: 0.4090 - val_binary_accuracy: 0.8048\nEpoch 26/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.4072 - binary_accuracy: 0.8079 - val_loss: 0.4113 - val_binary_accuracy: 0.8013\nEpoch 27/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.4076 - binary_accuracy: 0.7974 - val_loss: 0.4114 - val_binary_accuracy: 0.7954\nEpoch 28/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.4159 - binary_accuracy: 0.7939 - val_loss: 0.4061 - val_binary_accuracy: 0.8084\nEpoch 29/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.4071 - binary_accuracy: 0.8063 - val_loss: 0.4080 - val_binary_accuracy: 0.8066\nEpoch 30/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.4095 - binary_accuracy: 0.8000 - val_loss: 0.4078 - val_binary_accuracy: 0.8048\nEpoch 31/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.4025 - binary_accuracy: 0.8083 - val_loss: 0.4104 - val_binary_accuracy: 0.8013\nEpoch 32/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.4065 - binary_accuracy: 0.8022 - val_loss: 0.4081 - val_binary_accuracy: 0.8161\nEpoch 33/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.4080 - binary_accuracy: 0.8030 - val_loss: 0.4070 - val_binary_accuracy: 0.8043\nEpoch 34/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.4086 - binary_accuracy: 0.8036 - val_loss: 0.4094 - val_binary_accuracy: 0.8019\nEpoch 35/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.4076 - binary_accuracy: 0.8049 - val_loss: 0.4041 - val_binary_accuracy: 0.8078\nEpoch 36/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.4067 - binary_accuracy: 0.7982 - val_loss: 0.4064 - val_binary_accuracy: 0.8125\nEpoch 37/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.4055 - binary_accuracy: 0.8041 - val_loss: 0.4093 - val_binary_accuracy: 0.8090\nEpoch 38/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.4052 - binary_accuracy: 0.8071 - val_loss: 0.4092 - val_binary_accuracy: 0.8025\nEpoch 39/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.4040 - binary_accuracy: 0.8071 - val_loss: 0.4107 - val_binary_accuracy: 0.8031\nEpoch 40/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3988 - binary_accuracy: 0.8081 - val_loss: 0.4059 - val_binary_accuracy: 0.8048\nEpoch 41/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.4074 - binary_accuracy: 0.8006 - val_loss: 0.4040 - val_binary_accuracy: 0.8031\nEpoch 42/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.4047 - binary_accuracy: 0.8051 - val_loss: 0.4100 - val_binary_accuracy: 0.8025\nEpoch 43/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.4044 - binary_accuracy: 0.8065 - val_loss: 0.4058 - val_binary_accuracy: 0.8108\nEpoch 44/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3962 - binary_accuracy: 0.8103 - val_loss: 0.4041 - val_binary_accuracy: 0.8096\nEpoch 45/200\n20/20 [==============================] - 0s 21ms/step - loss: 0.4038 - binary_accuracy: 0.8045 - val_loss: 0.4074 - val_binary_accuracy: 0.8096\nEpoch 46/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3941 - binary_accuracy: 0.8108 - val_loss: 0.4039 - val_binary_accuracy: 0.8114\nEpoch 47/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.4003 - binary_accuracy: 0.8059 - val_loss: 0.4038 - val_binary_accuracy: 0.8054\nEpoch 48/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3961 - binary_accuracy: 0.8077 - val_loss: 0.4024 - val_binary_accuracy: 0.8037\nEpoch 49/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3952 - binary_accuracy: 0.8142 - val_loss: 0.4031 - val_binary_accuracy: 0.8060\nEpoch 50/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3937 - binary_accuracy: 0.8091 - val_loss: 0.4005 - val_binary_accuracy: 0.8060\nEpoch 51/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.4003 - binary_accuracy: 0.8061 - val_loss: 0.4020 - val_binary_accuracy: 0.8066\nEpoch 52/200\n20/20 [==============================] - 0s 23ms/step - loss: 0.3960 - binary_accuracy: 0.8075 - val_loss: 0.4013 - val_binary_accuracy: 0.8119\nEpoch 53/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3988 - binary_accuracy: 0.8105 - val_loss: 0.4005 - val_binary_accuracy: 0.8114\nEpoch 54/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3961 - binary_accuracy: 0.8126 - val_loss: 0.4024 - val_binary_accuracy: 0.8054\nEpoch 55/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3942 - binary_accuracy: 0.8116 - val_loss: 0.3994 - val_binary_accuracy: 0.8119\nEpoch 56/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3917 - binary_accuracy: 0.8108 - val_loss: 0.3978 - val_binary_accuracy: 0.8072\nEpoch 57/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3934 - binary_accuracy: 0.8122 - val_loss: 0.3972 - val_binary_accuracy: 0.8102\nEpoch 58/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3889 - binary_accuracy: 0.8150 - val_loss: 0.3990 - val_binary_accuracy: 0.8125\nEpoch 59/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3949 - binary_accuracy: 0.8130 - val_loss: 0.3962 - val_binary_accuracy: 0.7989\nEpoch 60/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3928 - binary_accuracy: 0.8065 - val_loss: 0.3986 - val_binary_accuracy: 0.8048\nEpoch 61/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3938 - binary_accuracy: 0.8043 - val_loss: 0.3965 - val_binary_accuracy: 0.8019\nEpoch 62/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3947 - binary_accuracy: 0.8122 - val_loss: 0.3999 - val_binary_accuracy: 0.8048\nEpoch 63/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3902 - binary_accuracy: 0.8124 - val_loss: 0.3957 - val_binary_accuracy: 0.8096\nEpoch 64/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3918 - binary_accuracy: 0.8075 - val_loss: 0.3962 - val_binary_accuracy: 0.8037\nEpoch 65/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3928 - binary_accuracy: 0.8093 - val_loss: 0.3979 - val_binary_accuracy: 0.8137\nEpoch 66/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3893 - binary_accuracy: 0.8130 - val_loss: 0.4008 - val_binary_accuracy: 0.8078\nEpoch 67/200\n20/20 [==============================] - 0s 18ms/step - loss: 0.3871 - binary_accuracy: 0.8138 - val_loss: 0.3952 - val_binary_accuracy: 0.8072\nEpoch 68/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3862 - binary_accuracy: 0.8114 - val_loss: 0.3969 - val_binary_accuracy: 0.7954\nEpoch 69/200\n20/20 [==============================] - 0s 18ms/step - loss: 0.3897 - binary_accuracy: 0.8093 - val_loss: 0.3990 - val_binary_accuracy: 0.8078\nEpoch 70/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3880 - binary_accuracy: 0.8124 - val_loss: 0.4023 - val_binary_accuracy: 0.8031\nEpoch 71/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3902 - binary_accuracy: 0.8164 - val_loss: 0.3942 - val_binary_accuracy: 0.8066\nEpoch 72/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3884 - binary_accuracy: 0.8103 - val_loss: 0.3967 - val_binary_accuracy: 0.8048\nEpoch 73/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3855 - binary_accuracy: 0.8105 - val_loss: 0.3953 - val_binary_accuracy: 0.8066\nEpoch 74/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3915 - binary_accuracy: 0.8093 - val_loss: 0.3961 - val_binary_accuracy: 0.8037\nEpoch 75/200\n20/20 [==============================] - 0s 18ms/step - loss: 0.3855 - binary_accuracy: 0.8152 - val_loss: 0.3948 - val_binary_accuracy: 0.8007\nEpoch 76/200\n20/20 [==============================] - 0s 18ms/step - loss: 0.3859 - binary_accuracy: 0.8099 - val_loss: 0.3942 - val_binary_accuracy: 0.8102\nEpoch 77/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3852 - binary_accuracy: 0.8120 - val_loss: 0.3987 - val_binary_accuracy: 0.8043\nEpoch 78/200\n20/20 [==============================] - 0s 18ms/step - loss: 0.3846 - binary_accuracy: 0.8075 - val_loss: 0.3943 - val_binary_accuracy: 0.8031\nEpoch 79/200\n20/20 [==============================] - 0s 18ms/step - loss: 0.3853 - binary_accuracy: 0.8172 - val_loss: 0.3978 - val_binary_accuracy: 0.8078\nEpoch 80/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3901 - binary_accuracy: 0.8103 - val_loss: 0.3903 - val_binary_accuracy: 0.8078\nEpoch 81/200\n20/20 [==============================] - 0s 22ms/step - loss: 0.3868 - binary_accuracy: 0.8065 - val_loss: 0.3938 - val_binary_accuracy: 0.8072\nEpoch 82/200\n20/20 [==============================] - 0s 18ms/step - loss: 0.3846 - binary_accuracy: 0.8097 - val_loss: 0.3882 - val_binary_accuracy: 0.8125\nEpoch 83/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3847 - binary_accuracy: 0.8140 - val_loss: 0.3924 - val_binary_accuracy: 0.8084\nEpoch 84/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3789 - binary_accuracy: 0.8140 - val_loss: 0.3887 - val_binary_accuracy: 0.8102\nEpoch 85/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3811 - binary_accuracy: 0.8201 - val_loss: 0.3893 - val_binary_accuracy: 0.8060\nEpoch 86/200\n20/20 [==============================] - 0s 18ms/step - loss: 0.3824 - binary_accuracy: 0.8181 - val_loss: 0.3909 - val_binary_accuracy: 0.8090\nEpoch 87/200\n20/20 [==============================] - 0s 21ms/step - loss: 0.3852 - binary_accuracy: 0.8087 - val_loss: 0.3869 - val_binary_accuracy: 0.8096\nEpoch 88/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3788 - binary_accuracy: 0.8160 - val_loss: 0.3916 - val_binary_accuracy: 0.8060\nEpoch 89/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3798 - binary_accuracy: 0.8166 - val_loss: 0.3882 - val_binary_accuracy: 0.8043\nEpoch 90/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3788 - binary_accuracy: 0.8154 - val_loss: 0.3845 - val_binary_accuracy: 0.8090\nEpoch 91/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3852 - binary_accuracy: 0.8063 - val_loss: 0.3853 - val_binary_accuracy: 0.8114\nEpoch 92/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3897 - binary_accuracy: 0.8110 - val_loss: 0.3868 - val_binary_accuracy: 0.8054\nEpoch 93/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3846 - binary_accuracy: 0.8156 - val_loss: 0.3904 - val_binary_accuracy: 0.8072\nEpoch 94/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3806 - binary_accuracy: 0.8199 - val_loss: 0.3871 - val_binary_accuracy: 0.8125\nEpoch 95/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3728 - binary_accuracy: 0.8176 - val_loss: 0.3855 - val_binary_accuracy: 0.8108\nEpoch 96/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3778 - binary_accuracy: 0.8260 - val_loss: 0.3881 - val_binary_accuracy: 0.8096\nEpoch 97/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3854 - binary_accuracy: 0.8138 - val_loss: 0.3813 - val_binary_accuracy: 0.8143\nEpoch 98/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3816 - binary_accuracy: 0.8162 - val_loss: 0.3935 - val_binary_accuracy: 0.8072\nEpoch 99/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3761 - binary_accuracy: 0.8146 - val_loss: 0.3815 - val_binary_accuracy: 0.8149\nEpoch 100/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3822 - binary_accuracy: 0.8136 - val_loss: 0.3887 - val_binary_accuracy: 0.8078\nEpoch 101/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3792 - binary_accuracy: 0.8166 - val_loss: 0.3879 - val_binary_accuracy: 0.8078\nEpoch 102/200\n20/20 [==============================] - 1s 26ms/step - loss: 0.3750 - binary_accuracy: 0.8187 - val_loss: 0.3854 - val_binary_accuracy: 0.8090\nEpoch 103/200\n20/20 [==============================] - 1s 47ms/step - loss: 0.3780 - binary_accuracy: 0.8146 - val_loss: 0.3878 - val_binary_accuracy: 0.8048\nEpoch 104/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3788 - binary_accuracy: 0.8158 - val_loss: 0.3827 - val_binary_accuracy: 0.8114\nEpoch 105/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3747 - binary_accuracy: 0.8166 - val_loss: 0.3854 - val_binary_accuracy: 0.8066\nEpoch 106/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3746 - binary_accuracy: 0.8126 - val_loss: 0.3887 - val_binary_accuracy: 0.8054\nEpoch 107/200\n20/20 [==============================] - 0s 22ms/step - loss: 0.3785 - binary_accuracy: 0.8142 - val_loss: 0.3836 - val_binary_accuracy: 0.8143\nEpoch 108/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3804 - binary_accuracy: 0.8150 - val_loss: 0.3900 - val_binary_accuracy: 0.8066\nEpoch 109/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3798 - binary_accuracy: 0.8112 - val_loss: 0.3806 - val_binary_accuracy: 0.8155\nEpoch 110/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3718 - binary_accuracy: 0.8189 - val_loss: 0.3803 - val_binary_accuracy: 0.8143\nEpoch 111/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3791 - binary_accuracy: 0.8168 - val_loss: 0.3822 - val_binary_accuracy: 0.8108\nEpoch 112/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3737 - binary_accuracy: 0.8170 - val_loss: 0.3785 - val_binary_accuracy: 0.8167\nEpoch 113/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3720 - binary_accuracy: 0.8205 - val_loss: 0.3813 - val_binary_accuracy: 0.8102\nEpoch 114/200\n20/20 [==============================] - 0s 18ms/step - loss: 0.3726 - binary_accuracy: 0.8166 - val_loss: 0.3838 - val_binary_accuracy: 0.8078\nEpoch 115/200\n20/20 [==============================] - 0s 18ms/step - loss: 0.3779 - binary_accuracy: 0.8191 - val_loss: 0.3792 - val_binary_accuracy: 0.8185\nEpoch 116/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3683 - binary_accuracy: 0.8203 - val_loss: 0.3815 - val_binary_accuracy: 0.8143\nEpoch 117/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3698 - binary_accuracy: 0.8245 - val_loss: 0.3803 - val_binary_accuracy: 0.8102\nEpoch 118/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3677 - binary_accuracy: 0.8233 - val_loss: 0.3771 - val_binary_accuracy: 0.8149\nEpoch 119/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3773 - binary_accuracy: 0.8152 - val_loss: 0.3840 - val_binary_accuracy: 0.8060\nEpoch 120/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3700 - binary_accuracy: 0.8201 - val_loss: 0.3812 - val_binary_accuracy: 0.8108\nEpoch 121/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3733 - binary_accuracy: 0.8176 - val_loss: 0.3850 - val_binary_accuracy: 0.8043\nEpoch 122/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3734 - binary_accuracy: 0.8166 - val_loss: 0.3827 - val_binary_accuracy: 0.8102\nEpoch 123/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3739 - binary_accuracy: 0.8168 - val_loss: 0.3812 - val_binary_accuracy: 0.8102\nEpoch 124/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3717 - binary_accuracy: 0.8193 - val_loss: 0.3820 - val_binary_accuracy: 0.8114\nEpoch 125/200\n20/20 [==============================] - 0s 21ms/step - loss: 0.3759 - binary_accuracy: 0.8170 - val_loss: 0.3770 - val_binary_accuracy: 0.8149\nEpoch 126/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3716 - binary_accuracy: 0.8201 - val_loss: 0.3811 - val_binary_accuracy: 0.8125\nEpoch 127/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3742 - binary_accuracy: 0.8158 - val_loss: 0.3834 - val_binary_accuracy: 0.8007\nEpoch 128/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3705 - binary_accuracy: 0.8201 - val_loss: 0.3779 - val_binary_accuracy: 0.8173\nEpoch 129/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3728 - binary_accuracy: 0.8183 - val_loss: 0.3833 - val_binary_accuracy: 0.8084\nEpoch 130/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3722 - binary_accuracy: 0.8215 - val_loss: 0.3840 - val_binary_accuracy: 0.8102\nEpoch 131/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3751 - binary_accuracy: 0.8144 - val_loss: 0.3814 - val_binary_accuracy: 0.8090\nEpoch 132/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3701 - binary_accuracy: 0.8209 - val_loss: 0.3790 - val_binary_accuracy: 0.8084\nEpoch 133/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3699 - binary_accuracy: 0.8189 - val_loss: 0.3791 - val_binary_accuracy: 0.8125\nEpoch 134/200\n20/20 [==============================] - 0s 21ms/step - loss: 0.3643 - binary_accuracy: 0.8276 - val_loss: 0.3809 - val_binary_accuracy: 0.8137\nEpoch 135/200\n20/20 [==============================] - 0s 22ms/step - loss: 0.3726 - binary_accuracy: 0.8189 - val_loss: 0.3789 - val_binary_accuracy: 0.8185\nEpoch 136/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3708 - binary_accuracy: 0.8193 - val_loss: 0.3825 - val_binary_accuracy: 0.8096\nEpoch 137/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3681 - binary_accuracy: 0.8205 - val_loss: 0.3848 - val_binary_accuracy: 0.8090\nEpoch 138/200\n20/20 [==============================] - 0s 20ms/step - loss: 0.3686 - binary_accuracy: 0.8221 - val_loss: 0.3900 - val_binary_accuracy: 0.8013\nEpoch 1/200\n20/20 [==============================] - 2s 28ms/step - loss: 0.6398 - binary_accuracy: 0.6915 - val_loss: 0.4939 - val_binary_accuracy: 0.7741\nEpoch 2/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.5416 - binary_accuracy: 0.7406 - val_loss: 0.4672 - val_binary_accuracy: 0.7847\nEpoch 3/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.5084 - binary_accuracy: 0.7527 - val_loss: 0.4522 - val_binary_accuracy: 0.7936\nEpoch 4/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.4846 - binary_accuracy: 0.7659 - val_loss: 0.4432 - val_binary_accuracy: 0.7978\nEpoch 5/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.4684 - binary_accuracy: 0.7684 - val_loss: 0.4390 - val_binary_accuracy: 0.7936\nEpoch 6/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4665 - binary_accuracy: 0.7704 - val_loss: 0.4308 - val_binary_accuracy: 0.8031\nEpoch 7/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4530 - binary_accuracy: 0.7722 - val_loss: 0.4274 - val_binary_accuracy: 0.8025\nEpoch 8/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4553 - binary_accuracy: 0.7811 - val_loss: 0.4239 - val_binary_accuracy: 0.8001\nEpoch 9/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.4479 - binary_accuracy: 0.7761 - val_loss: 0.4198 - val_binary_accuracy: 0.7989\nEpoch 10/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.4425 - binary_accuracy: 0.7830 - val_loss: 0.4184 - val_binary_accuracy: 0.8013\nEpoch 11/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.4305 - binary_accuracy: 0.7919 - val_loss: 0.4171 - val_binary_accuracy: 0.8025\nEpoch 12/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.4282 - binary_accuracy: 0.7893 - val_loss: 0.4164 - val_binary_accuracy: 0.8007\nEpoch 13/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.4350 - binary_accuracy: 0.7929 - val_loss: 0.4156 - val_binary_accuracy: 0.7989\nEpoch 14/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4298 - binary_accuracy: 0.7907 - val_loss: 0.4151 - val_binary_accuracy: 0.7960\nEpoch 15/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.4291 - binary_accuracy: 0.7953 - val_loss: 0.4147 - val_binary_accuracy: 0.8031\nEpoch 16/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.4244 - binary_accuracy: 0.7959 - val_loss: 0.4133 - val_binary_accuracy: 0.8001\nEpoch 17/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4208 - binary_accuracy: 0.7963 - val_loss: 0.4119 - val_binary_accuracy: 0.7995\nEpoch 18/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4186 - binary_accuracy: 0.7923 - val_loss: 0.4128 - val_binary_accuracy: 0.8001\nEpoch 19/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.4225 - binary_accuracy: 0.7972 - val_loss: 0.4120 - val_binary_accuracy: 0.7972\nEpoch 20/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4151 - binary_accuracy: 0.7972 - val_loss: 0.4116 - val_binary_accuracy: 0.8048\nEpoch 21/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4077 - binary_accuracy: 0.8034 - val_loss: 0.4126 - val_binary_accuracy: 0.7989\nEpoch 22/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4159 - binary_accuracy: 0.7990 - val_loss: 0.4103 - val_binary_accuracy: 0.7983\nEpoch 23/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.4112 - binary_accuracy: 0.8012 - val_loss: 0.4109 - val_binary_accuracy: 0.7995\nEpoch 24/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4124 - binary_accuracy: 0.8039 - val_loss: 0.4115 - val_binary_accuracy: 0.8037\nEpoch 25/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4139 - binary_accuracy: 0.7994 - val_loss: 0.4130 - val_binary_accuracy: 0.8037\nEpoch 26/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4109 - binary_accuracy: 0.8055 - val_loss: 0.4142 - val_binary_accuracy: 0.8054\nEpoch 27/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4072 - binary_accuracy: 0.8010 - val_loss: 0.4125 - val_binary_accuracy: 0.7978\nEpoch 28/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.4004 - binary_accuracy: 0.8130 - val_loss: 0.4113 - val_binary_accuracy: 0.7966\nEpoch 29/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.4078 - binary_accuracy: 0.8034 - val_loss: 0.4082 - val_binary_accuracy: 0.8007\nEpoch 30/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4093 - binary_accuracy: 0.8020 - val_loss: 0.4081 - val_binary_accuracy: 0.7966\nEpoch 31/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.4070 - binary_accuracy: 0.8034 - val_loss: 0.4078 - val_binary_accuracy: 0.8001\nEpoch 32/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.4097 - binary_accuracy: 0.8028 - val_loss: 0.4073 - val_binary_accuracy: 0.8025\nEpoch 33/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4043 - binary_accuracy: 0.8037 - val_loss: 0.4073 - val_binary_accuracy: 0.8001\nEpoch 34/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.4077 - binary_accuracy: 0.8022 - val_loss: 0.4070 - val_binary_accuracy: 0.8001\nEpoch 35/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.4030 - binary_accuracy: 0.8101 - val_loss: 0.4069 - val_binary_accuracy: 0.7978\nEpoch 36/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4036 - binary_accuracy: 0.8053 - val_loss: 0.4085 - val_binary_accuracy: 0.8060\nEpoch 37/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.4032 - binary_accuracy: 0.8081 - val_loss: 0.4058 - val_binary_accuracy: 0.8031\nEpoch 38/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3989 - binary_accuracy: 0.8120 - val_loss: 0.4077 - val_binary_accuracy: 0.8066\nEpoch 39/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4019 - binary_accuracy: 0.8101 - val_loss: 0.4078 - val_binary_accuracy: 0.8037\nEpoch 40/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.4008 - binary_accuracy: 0.8112 - val_loss: 0.4073 - val_binary_accuracy: 0.8054\nEpoch 41/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3917 - binary_accuracy: 0.8172 - val_loss: 0.4088 - val_binary_accuracy: 0.8037\nEpoch 42/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3951 - binary_accuracy: 0.8158 - val_loss: 0.4075 - val_binary_accuracy: 0.8037\nEpoch 43/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3998 - binary_accuracy: 0.8002 - val_loss: 0.4061 - val_binary_accuracy: 0.8048\nEpoch 44/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3940 - binary_accuracy: 0.8124 - val_loss: 0.4053 - val_binary_accuracy: 0.8043\nEpoch 45/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3940 - binary_accuracy: 0.8091 - val_loss: 0.4065 - val_binary_accuracy: 0.8048\nEpoch 46/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3962 - binary_accuracy: 0.8138 - val_loss: 0.4024 - val_binary_accuracy: 0.8025\nEpoch 47/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3926 - binary_accuracy: 0.8120 - val_loss: 0.4035 - val_binary_accuracy: 0.8025\nEpoch 48/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3952 - binary_accuracy: 0.8097 - val_loss: 0.4044 - val_binary_accuracy: 0.8060\nEpoch 49/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3970 - binary_accuracy: 0.8112 - val_loss: 0.4032 - val_binary_accuracy: 0.8031\nEpoch 50/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3920 - binary_accuracy: 0.8134 - val_loss: 0.4028 - val_binary_accuracy: 0.8037\nEpoch 51/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3895 - binary_accuracy: 0.8146 - val_loss: 0.4040 - val_binary_accuracy: 0.8054\nEpoch 52/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3943 - binary_accuracy: 0.8089 - val_loss: 0.4008 - val_binary_accuracy: 0.8037\nEpoch 53/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3884 - binary_accuracy: 0.8120 - val_loss: 0.3995 - val_binary_accuracy: 0.8066\nEpoch 54/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3926 - binary_accuracy: 0.8095 - val_loss: 0.3993 - val_binary_accuracy: 0.8043\nEpoch 55/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3947 - binary_accuracy: 0.8065 - val_loss: 0.3985 - val_binary_accuracy: 0.8084\nEpoch 56/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3929 - binary_accuracy: 0.8128 - val_loss: 0.4013 - val_binary_accuracy: 0.8066\nEpoch 57/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3907 - binary_accuracy: 0.8055 - val_loss: 0.3976 - val_binary_accuracy: 0.8048\nEpoch 58/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3925 - binary_accuracy: 0.8132 - val_loss: 0.3988 - val_binary_accuracy: 0.8060\nEpoch 59/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3884 - binary_accuracy: 0.8134 - val_loss: 0.4006 - val_binary_accuracy: 0.8054\nEpoch 60/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3825 - binary_accuracy: 0.8174 - val_loss: 0.3976 - val_binary_accuracy: 0.8096\nEpoch 61/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3910 - binary_accuracy: 0.8118 - val_loss: 0.3989 - val_binary_accuracy: 0.8072\nEpoch 62/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3868 - binary_accuracy: 0.8124 - val_loss: 0.3960 - val_binary_accuracy: 0.8108\nEpoch 63/200\n20/20 [==============================] - 0s 24ms/step - loss: 0.3918 - binary_accuracy: 0.8120 - val_loss: 0.3936 - val_binary_accuracy: 0.8048\nEpoch 64/200\n20/20 [==============================] - 0s 22ms/step - loss: 0.3816 - binary_accuracy: 0.8162 - val_loss: 0.3942 - val_binary_accuracy: 0.8084\nEpoch 65/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3848 - binary_accuracy: 0.8075 - val_loss: 0.3937 - val_binary_accuracy: 0.8048\nEpoch 66/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3810 - binary_accuracy: 0.8085 - val_loss: 0.3922 - val_binary_accuracy: 0.8066\nEpoch 67/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3874 - binary_accuracy: 0.8108 - val_loss: 0.3940 - val_binary_accuracy: 0.8066\nEpoch 68/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3820 - binary_accuracy: 0.8185 - val_loss: 0.3935 - val_binary_accuracy: 0.8090\nEpoch 69/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3846 - binary_accuracy: 0.8105 - val_loss: 0.3954 - val_binary_accuracy: 0.8078\nEpoch 70/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3894 - binary_accuracy: 0.8089 - val_loss: 0.3956 - val_binary_accuracy: 0.8072\nEpoch 71/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3841 - binary_accuracy: 0.8189 - val_loss: 0.3924 - val_binary_accuracy: 0.8043\nEpoch 72/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3876 - binary_accuracy: 0.8181 - val_loss: 0.3923 - val_binary_accuracy: 0.8066\nEpoch 73/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3820 - binary_accuracy: 0.8107 - val_loss: 0.3920 - val_binary_accuracy: 0.8048\nEpoch 74/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3821 - binary_accuracy: 0.8166 - val_loss: 0.3926 - val_binary_accuracy: 0.8037\nEpoch 75/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3837 - binary_accuracy: 0.8122 - val_loss: 0.3898 - val_binary_accuracy: 0.8066\nEpoch 76/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3896 - binary_accuracy: 0.8101 - val_loss: 0.3897 - val_binary_accuracy: 0.8054\nEpoch 77/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3776 - binary_accuracy: 0.8215 - val_loss: 0.3912 - val_binary_accuracy: 0.8054\nEpoch 78/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3794 - binary_accuracy: 0.8170 - val_loss: 0.3916 - val_binary_accuracy: 0.8048\nEpoch 79/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3797 - binary_accuracy: 0.8150 - val_loss: 0.3896 - val_binary_accuracy: 0.8066\nEpoch 80/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3827 - binary_accuracy: 0.8130 - val_loss: 0.3878 - val_binary_accuracy: 0.8084\nEpoch 81/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3826 - binary_accuracy: 0.8134 - val_loss: 0.3899 - val_binary_accuracy: 0.8096\nEpoch 82/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3796 - binary_accuracy: 0.8185 - val_loss: 0.3887 - val_binary_accuracy: 0.8078\nEpoch 83/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3820 - binary_accuracy: 0.8156 - val_loss: 0.3885 - val_binary_accuracy: 0.8102\nEpoch 84/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3832 - binary_accuracy: 0.8112 - val_loss: 0.3911 - val_binary_accuracy: 0.8066\nEpoch 85/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3774 - binary_accuracy: 0.8112 - val_loss: 0.3895 - val_binary_accuracy: 0.8054\nEpoch 86/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3731 - binary_accuracy: 0.8207 - val_loss: 0.3881 - val_binary_accuracy: 0.8108\nEpoch 87/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3742 - binary_accuracy: 0.8181 - val_loss: 0.3902 - val_binary_accuracy: 0.8060\nEpoch 88/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3789 - binary_accuracy: 0.8144 - val_loss: 0.3888 - val_binary_accuracy: 0.8054\nEpoch 89/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3767 - binary_accuracy: 0.8191 - val_loss: 0.3870 - val_binary_accuracy: 0.8078\nEpoch 90/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3778 - binary_accuracy: 0.8187 - val_loss: 0.3882 - val_binary_accuracy: 0.8060\nEpoch 91/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3703 - binary_accuracy: 0.8239 - val_loss: 0.3888 - val_binary_accuracy: 0.8108\nEpoch 92/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3767 - binary_accuracy: 0.8185 - val_loss: 0.3879 - val_binary_accuracy: 0.8060\nEpoch 93/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3793 - binary_accuracy: 0.8197 - val_loss: 0.3871 - val_binary_accuracy: 0.8072\nEpoch 94/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3761 - binary_accuracy: 0.8213 - val_loss: 0.3864 - val_binary_accuracy: 0.8054\nEpoch 95/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3775 - binary_accuracy: 0.8178 - val_loss: 0.3838 - val_binary_accuracy: 0.8143\nEpoch 96/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3718 - binary_accuracy: 0.8193 - val_loss: 0.3820 - val_binary_accuracy: 0.8096\nEpoch 97/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3793 - binary_accuracy: 0.8189 - val_loss: 0.3840 - val_binary_accuracy: 0.8072\nEpoch 98/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3763 - binary_accuracy: 0.8207 - val_loss: 0.3840 - val_binary_accuracy: 0.8114\nEpoch 99/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3784 - binary_accuracy: 0.8110 - val_loss: 0.3834 - val_binary_accuracy: 0.8119\nEpoch 100/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3762 - binary_accuracy: 0.8201 - val_loss: 0.3823 - val_binary_accuracy: 0.8143\nEpoch 101/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3772 - binary_accuracy: 0.8162 - val_loss: 0.3833 - val_binary_accuracy: 0.8066\nEpoch 102/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3738 - binary_accuracy: 0.8211 - val_loss: 0.3833 - val_binary_accuracy: 0.8072\nEpoch 103/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3784 - binary_accuracy: 0.8118 - val_loss: 0.3841 - val_binary_accuracy: 0.8119\nEpoch 104/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3714 - binary_accuracy: 0.8247 - val_loss: 0.3817 - val_binary_accuracy: 0.8143\nEpoch 105/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3764 - binary_accuracy: 0.8191 - val_loss: 0.3816 - val_binary_accuracy: 0.8066\nEpoch 106/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3715 - binary_accuracy: 0.8205 - val_loss: 0.3807 - val_binary_accuracy: 0.8125\nEpoch 107/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3665 - binary_accuracy: 0.8241 - val_loss: 0.3806 - val_binary_accuracy: 0.8114\nEpoch 108/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3730 - binary_accuracy: 0.8197 - val_loss: 0.3798 - val_binary_accuracy: 0.8119\nEpoch 109/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3712 - binary_accuracy: 0.8142 - val_loss: 0.3782 - val_binary_accuracy: 0.8167\nEpoch 110/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3692 - binary_accuracy: 0.8221 - val_loss: 0.3789 - val_binary_accuracy: 0.8114\nEpoch 111/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3728 - binary_accuracy: 0.8179 - val_loss: 0.3792 - val_binary_accuracy: 0.8090\nEpoch 112/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3732 - binary_accuracy: 0.8160 - val_loss: 0.3790 - val_binary_accuracy: 0.8137\nEpoch 113/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3711 - binary_accuracy: 0.8176 - val_loss: 0.3820 - val_binary_accuracy: 0.8078\nEpoch 114/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3749 - binary_accuracy: 0.8174 - val_loss: 0.3810 - val_binary_accuracy: 0.8102\nEpoch 115/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3690 - binary_accuracy: 0.8241 - val_loss: 0.3794 - val_binary_accuracy: 0.8084\nEpoch 116/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3671 - binary_accuracy: 0.8223 - val_loss: 0.3813 - val_binary_accuracy: 0.8155\nEpoch 117/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3711 - binary_accuracy: 0.8215 - val_loss: 0.3809 - val_binary_accuracy: 0.8108\nEpoch 118/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3650 - binary_accuracy: 0.8229 - val_loss: 0.3780 - val_binary_accuracy: 0.8137\nEpoch 119/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3750 - binary_accuracy: 0.8185 - val_loss: 0.3783 - val_binary_accuracy: 0.8119\nEpoch 120/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3696 - binary_accuracy: 0.8193 - val_loss: 0.3779 - val_binary_accuracy: 0.8131\nEpoch 121/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3677 - binary_accuracy: 0.8187 - val_loss: 0.3782 - val_binary_accuracy: 0.8155\nEpoch 122/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3684 - binary_accuracy: 0.8191 - val_loss: 0.3785 - val_binary_accuracy: 0.8108\nEpoch 123/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3642 - binary_accuracy: 0.8343 - val_loss: 0.3766 - val_binary_accuracy: 0.8090\nEpoch 124/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3679 - binary_accuracy: 0.8178 - val_loss: 0.3783 - val_binary_accuracy: 0.8131\nEpoch 125/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3679 - binary_accuracy: 0.8221 - val_loss: 0.3785 - val_binary_accuracy: 0.8119\nEpoch 126/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3655 - binary_accuracy: 0.8280 - val_loss: 0.3769 - val_binary_accuracy: 0.8155\nEpoch 127/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3757 - binary_accuracy: 0.8136 - val_loss: 0.3752 - val_binary_accuracy: 0.8196\nEpoch 128/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3663 - binary_accuracy: 0.8239 - val_loss: 0.3782 - val_binary_accuracy: 0.8125\nEpoch 129/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3684 - binary_accuracy: 0.8239 - val_loss: 0.3790 - val_binary_accuracy: 0.8119\nEpoch 130/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3628 - binary_accuracy: 0.8290 - val_loss: 0.3773 - val_binary_accuracy: 0.8108\nEpoch 131/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3698 - binary_accuracy: 0.8229 - val_loss: 0.3811 - val_binary_accuracy: 0.8119\nEpoch 132/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3698 - binary_accuracy: 0.8179 - val_loss: 0.3808 - val_binary_accuracy: 0.8102\nEpoch 133/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3626 - binary_accuracy: 0.8225 - val_loss: 0.3778 - val_binary_accuracy: 0.8196\nEpoch 134/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3626 - binary_accuracy: 0.8221 - val_loss: 0.3819 - val_binary_accuracy: 0.8090\nEpoch 135/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3703 - binary_accuracy: 0.8142 - val_loss: 0.3772 - val_binary_accuracy: 0.8131\nEpoch 136/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3670 - binary_accuracy: 0.8260 - val_loss: 0.3757 - val_binary_accuracy: 0.8179\nEpoch 137/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3667 - binary_accuracy: 0.8247 - val_loss: 0.3789 - val_binary_accuracy: 0.8102\nEpoch 138/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3615 - binary_accuracy: 0.8276 - val_loss: 0.3762 - val_binary_accuracy: 0.8149\nEpoch 139/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3611 - binary_accuracy: 0.8231 - val_loss: 0.3781 - val_binary_accuracy: 0.8119\nEpoch 140/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3656 - binary_accuracy: 0.8229 - val_loss: 0.3836 - val_binary_accuracy: 0.8037\nEpoch 141/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3717 - binary_accuracy: 0.8187 - val_loss: 0.3763 - val_binary_accuracy: 0.8143\nEpoch 142/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3650 - binary_accuracy: 0.8211 - val_loss: 0.3801 - val_binary_accuracy: 0.8119\nEpoch 143/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3638 - binary_accuracy: 0.8229 - val_loss: 0.3786 - val_binary_accuracy: 0.8114\nEpoch 144/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3603 - binary_accuracy: 0.8256 - val_loss: 0.3780 - val_binary_accuracy: 0.8143\nEpoch 145/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3607 - binary_accuracy: 0.8213 - val_loss: 0.3772 - val_binary_accuracy: 0.8173\nEpoch 146/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3625 - binary_accuracy: 0.8258 - val_loss: 0.3785 - val_binary_accuracy: 0.8090\nEpoch 147/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3634 - binary_accuracy: 0.8217 - val_loss: 0.3759 - val_binary_accuracy: 0.8149\nEpoch 1/200\n20/20 [==============================] - 2s 28ms/step - loss: 0.6564 - binary_accuracy: 0.6736 - val_loss: 0.5252 - val_binary_accuracy: 0.7830\nEpoch 2/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.5299 - binary_accuracy: 0.7383 - val_loss: 0.5019 - val_binary_accuracy: 0.7924\nEpoch 3/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.5017 - binary_accuracy: 0.7535 - val_loss: 0.4745 - val_binary_accuracy: 0.7960\nEpoch 4/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4842 - binary_accuracy: 0.7651 - val_loss: 0.4585 - val_binary_accuracy: 0.8001\nEpoch 5/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4791 - binary_accuracy: 0.7641 - val_loss: 0.4450 - val_binary_accuracy: 0.8019\nEpoch 6/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4628 - binary_accuracy: 0.7716 - val_loss: 0.4377 - val_binary_accuracy: 0.7989\nEpoch 7/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4601 - binary_accuracy: 0.7751 - val_loss: 0.4293 - val_binary_accuracy: 0.8007\nEpoch 8/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4518 - binary_accuracy: 0.7807 - val_loss: 0.4239 - val_binary_accuracy: 0.8037\nEpoch 9/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.4379 - binary_accuracy: 0.7815 - val_loss: 0.4206 - val_binary_accuracy: 0.8043\nEpoch 10/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4411 - binary_accuracy: 0.7844 - val_loss: 0.4185 - val_binary_accuracy: 0.8037\nEpoch 11/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4314 - binary_accuracy: 0.7826 - val_loss: 0.4130 - val_binary_accuracy: 0.8043\nEpoch 12/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4303 - binary_accuracy: 0.7854 - val_loss: 0.4142 - val_binary_accuracy: 0.7989\nEpoch 13/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4325 - binary_accuracy: 0.7876 - val_loss: 0.4120 - val_binary_accuracy: 0.8025\nEpoch 14/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4262 - binary_accuracy: 0.7927 - val_loss: 0.4113 - val_binary_accuracy: 0.8007\nEpoch 15/200\n20/20 [==============================] - 0s 16ms/step - loss: 0.4205 - binary_accuracy: 0.7994 - val_loss: 0.4108 - val_binary_accuracy: 0.7989\nEpoch 16/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4178 - binary_accuracy: 0.7943 - val_loss: 0.4104 - val_binary_accuracy: 0.8043\nEpoch 17/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4215 - binary_accuracy: 0.7897 - val_loss: 0.4074 - val_binary_accuracy: 0.8019\nEpoch 18/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.4231 - binary_accuracy: 0.7951 - val_loss: 0.4074 - val_binary_accuracy: 0.8019\nEpoch 19/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4154 - binary_accuracy: 0.7984 - val_loss: 0.4076 - val_binary_accuracy: 0.7995\nEpoch 20/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4202 - binary_accuracy: 0.8000 - val_loss: 0.4067 - val_binary_accuracy: 0.8013\nEpoch 21/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4096 - binary_accuracy: 0.7974 - val_loss: 0.4064 - val_binary_accuracy: 0.8019\nEpoch 22/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4153 - binary_accuracy: 0.7951 - val_loss: 0.4077 - val_binary_accuracy: 0.7989\nEpoch 23/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4115 - binary_accuracy: 0.7992 - val_loss: 0.4067 - val_binary_accuracy: 0.7983\nEpoch 24/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4143 - binary_accuracy: 0.8026 - val_loss: 0.4044 - val_binary_accuracy: 0.8048\nEpoch 25/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4079 - binary_accuracy: 0.7996 - val_loss: 0.4052 - val_binary_accuracy: 0.8007\nEpoch 26/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.4093 - binary_accuracy: 0.7992 - val_loss: 0.4028 - val_binary_accuracy: 0.8048\nEpoch 27/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4074 - binary_accuracy: 0.8097 - val_loss: 0.4042 - val_binary_accuracy: 0.8037\nEpoch 28/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4020 - binary_accuracy: 0.8039 - val_loss: 0.4059 - val_binary_accuracy: 0.8001\nEpoch 29/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4022 - binary_accuracy: 0.8059 - val_loss: 0.4004 - val_binary_accuracy: 0.8031\nEpoch 30/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4013 - binary_accuracy: 0.8034 - val_loss: 0.4026 - val_binary_accuracy: 0.8048\nEpoch 31/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4044 - binary_accuracy: 0.8012 - val_loss: 0.4032 - val_binary_accuracy: 0.8037\nEpoch 32/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4010 - binary_accuracy: 0.8055 - val_loss: 0.4015 - val_binary_accuracy: 0.8031\nEpoch 33/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4085 - binary_accuracy: 0.8036 - val_loss: 0.4013 - val_binary_accuracy: 0.8072\nEpoch 34/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3980 - binary_accuracy: 0.8055 - val_loss: 0.4008 - val_binary_accuracy: 0.8031\nEpoch 35/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3955 - binary_accuracy: 0.8071 - val_loss: 0.4013 - val_binary_accuracy: 0.8048\nEpoch 36/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.4006 - binary_accuracy: 0.8051 - val_loss: 0.4006 - val_binary_accuracy: 0.8048\nEpoch 37/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3954 - binary_accuracy: 0.8105 - val_loss: 0.3991 - val_binary_accuracy: 0.7995\nEpoch 38/200\n20/20 [==============================] - 1s 30ms/step - loss: 0.3961 - binary_accuracy: 0.8079 - val_loss: 0.3987 - val_binary_accuracy: 0.8060\nEpoch 39/200\n20/20 [==============================] - 0s 18ms/step - loss: 0.3999 - binary_accuracy: 0.8091 - val_loss: 0.3996 - val_binary_accuracy: 0.8019\nEpoch 40/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3951 - binary_accuracy: 0.8093 - val_loss: 0.3969 - val_binary_accuracy: 0.8025\nEpoch 41/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3940 - binary_accuracy: 0.8099 - val_loss: 0.3966 - val_binary_accuracy: 0.8054\nEpoch 42/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3929 - binary_accuracy: 0.8138 - val_loss: 0.3955 - val_binary_accuracy: 0.8025\nEpoch 43/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.4010 - binary_accuracy: 0.8089 - val_loss: 0.3982 - val_binary_accuracy: 0.8060\nEpoch 44/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3931 - binary_accuracy: 0.8061 - val_loss: 0.3956 - val_binary_accuracy: 0.8066\nEpoch 45/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3909 - binary_accuracy: 0.8136 - val_loss: 0.3953 - val_binary_accuracy: 0.8078\nEpoch 46/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3883 - binary_accuracy: 0.8181 - val_loss: 0.3950 - val_binary_accuracy: 0.8066\nEpoch 47/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3973 - binary_accuracy: 0.8087 - val_loss: 0.3962 - val_binary_accuracy: 0.8060\nEpoch 48/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3892 - binary_accuracy: 0.8112 - val_loss: 0.3946 - val_binary_accuracy: 0.8025\nEpoch 49/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3927 - binary_accuracy: 0.8122 - val_loss: 0.3934 - val_binary_accuracy: 0.8060\nEpoch 50/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3901 - binary_accuracy: 0.8136 - val_loss: 0.3937 - val_binary_accuracy: 0.8060\nEpoch 51/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3885 - binary_accuracy: 0.8124 - val_loss: 0.3941 - val_binary_accuracy: 0.8078\nEpoch 52/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3890 - binary_accuracy: 0.8160 - val_loss: 0.3926 - val_binary_accuracy: 0.8060\nEpoch 53/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3853 - binary_accuracy: 0.8146 - val_loss: 0.3910 - val_binary_accuracy: 0.8037\nEpoch 54/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3943 - binary_accuracy: 0.8075 - val_loss: 0.3918 - val_binary_accuracy: 0.8054\nEpoch 55/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3835 - binary_accuracy: 0.8152 - val_loss: 0.3915 - val_binary_accuracy: 0.8090\nEpoch 56/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3837 - binary_accuracy: 0.8140 - val_loss: 0.3925 - val_binary_accuracy: 0.8078\nEpoch 57/200\n20/20 [==============================] - 0s 16ms/step - loss: 0.3833 - binary_accuracy: 0.8126 - val_loss: 0.3925 - val_binary_accuracy: 0.8102\nEpoch 58/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3883 - binary_accuracy: 0.8114 - val_loss: 0.3917 - val_binary_accuracy: 0.8066\nEpoch 59/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3812 - binary_accuracy: 0.8189 - val_loss: 0.3915 - val_binary_accuracy: 0.8072\nEpoch 60/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3887 - binary_accuracy: 0.8128 - val_loss: 0.3934 - val_binary_accuracy: 0.8084\nEpoch 61/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3878 - binary_accuracy: 0.8128 - val_loss: 0.3910 - val_binary_accuracy: 0.8078\nEpoch 62/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3840 - binary_accuracy: 0.8148 - val_loss: 0.3928 - val_binary_accuracy: 0.8102\nEpoch 63/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3851 - binary_accuracy: 0.8162 - val_loss: 0.3918 - val_binary_accuracy: 0.8090\nEpoch 64/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3788 - binary_accuracy: 0.8156 - val_loss: 0.3898 - val_binary_accuracy: 0.8108\nEpoch 65/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3768 - binary_accuracy: 0.8201 - val_loss: 0.3914 - val_binary_accuracy: 0.8114\nEpoch 66/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3776 - binary_accuracy: 0.8140 - val_loss: 0.3883 - val_binary_accuracy: 0.8131\nEpoch 67/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3799 - binary_accuracy: 0.8201 - val_loss: 0.3901 - val_binary_accuracy: 0.8084\nEpoch 68/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3813 - binary_accuracy: 0.8132 - val_loss: 0.3866 - val_binary_accuracy: 0.8090\nEpoch 69/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3765 - binary_accuracy: 0.8197 - val_loss: 0.3888 - val_binary_accuracy: 0.8096\nEpoch 70/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3801 - binary_accuracy: 0.8172 - val_loss: 0.3856 - val_binary_accuracy: 0.8131\nEpoch 71/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3785 - binary_accuracy: 0.8193 - val_loss: 0.3874 - val_binary_accuracy: 0.8114\nEpoch 72/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3770 - binary_accuracy: 0.8199 - val_loss: 0.3876 - val_binary_accuracy: 0.8054\nEpoch 73/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3750 - binary_accuracy: 0.8195 - val_loss: 0.3859 - val_binary_accuracy: 0.8084\nEpoch 74/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3812 - binary_accuracy: 0.8138 - val_loss: 0.3841 - val_binary_accuracy: 0.8066\nEpoch 75/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3761 - binary_accuracy: 0.8181 - val_loss: 0.3851 - val_binary_accuracy: 0.8072\nEpoch 76/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3747 - binary_accuracy: 0.8124 - val_loss: 0.3842 - val_binary_accuracy: 0.8119\nEpoch 77/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3892 - binary_accuracy: 0.8097 - val_loss: 0.3838 - val_binary_accuracy: 0.8084\nEpoch 78/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3725 - binary_accuracy: 0.8199 - val_loss: 0.3817 - val_binary_accuracy: 0.8048\nEpoch 79/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3705 - binary_accuracy: 0.8178 - val_loss: 0.3868 - val_binary_accuracy: 0.8072\nEpoch 80/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3728 - binary_accuracy: 0.8205 - val_loss: 0.3860 - val_binary_accuracy: 0.8096\nEpoch 81/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3671 - binary_accuracy: 0.8237 - val_loss: 0.3836 - val_binary_accuracy: 0.8096\nEpoch 82/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3729 - binary_accuracy: 0.8203 - val_loss: 0.3833 - val_binary_accuracy: 0.8078\nEpoch 83/200\n20/20 [==============================] - 0s 11ms/step - loss: 0.3743 - binary_accuracy: 0.8193 - val_loss: 0.3860 - val_binary_accuracy: 0.8090\nEpoch 84/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3710 - binary_accuracy: 0.8187 - val_loss: 0.3851 - val_binary_accuracy: 0.8084\nEpoch 85/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3644 - binary_accuracy: 0.8241 - val_loss: 0.3818 - val_binary_accuracy: 0.8114\nEpoch 86/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3754 - binary_accuracy: 0.8179 - val_loss: 0.3828 - val_binary_accuracy: 0.8131\nEpoch 87/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3694 - binary_accuracy: 0.8207 - val_loss: 0.3797 - val_binary_accuracy: 0.8137\nEpoch 88/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3717 - binary_accuracy: 0.8164 - val_loss: 0.3799 - val_binary_accuracy: 0.8084\nEpoch 89/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3689 - binary_accuracy: 0.8221 - val_loss: 0.3822 - val_binary_accuracy: 0.8096\nEpoch 90/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3713 - binary_accuracy: 0.8189 - val_loss: 0.3805 - val_binary_accuracy: 0.8078\nEpoch 91/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3689 - binary_accuracy: 0.8215 - val_loss: 0.3809 - val_binary_accuracy: 0.8102\nEpoch 92/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3664 - binary_accuracy: 0.8249 - val_loss: 0.3769 - val_binary_accuracy: 0.8137\nEpoch 93/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3677 - binary_accuracy: 0.8221 - val_loss: 0.3784 - val_binary_accuracy: 0.8125\nEpoch 94/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3655 - binary_accuracy: 0.8170 - val_loss: 0.3806 - val_binary_accuracy: 0.8108\nEpoch 95/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3643 - binary_accuracy: 0.8197 - val_loss: 0.3792 - val_binary_accuracy: 0.8096\nEpoch 96/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3773 - binary_accuracy: 0.8195 - val_loss: 0.3822 - val_binary_accuracy: 0.8060\nEpoch 97/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3658 - binary_accuracy: 0.8215 - val_loss: 0.3789 - val_binary_accuracy: 0.8090\nEpoch 98/200\n20/20 [==============================] - 0s 13ms/step - loss: 0.3690 - binary_accuracy: 0.8213 - val_loss: 0.3779 - val_binary_accuracy: 0.8114\nEpoch 99/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3675 - binary_accuracy: 0.8250 - val_loss: 0.3782 - val_binary_accuracy: 0.8131\nEpoch 100/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3692 - binary_accuracy: 0.8201 - val_loss: 0.3800 - val_binary_accuracy: 0.8060\nEpoch 101/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3668 - binary_accuracy: 0.8211 - val_loss: 0.3809 - val_binary_accuracy: 0.8090\nEpoch 102/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3616 - binary_accuracy: 0.8262 - val_loss: 0.3798 - val_binary_accuracy: 0.8090\nEpoch 103/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3691 - binary_accuracy: 0.8187 - val_loss: 0.3795 - val_binary_accuracy: 0.8108\nEpoch 104/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3657 - binary_accuracy: 0.8229 - val_loss: 0.3779 - val_binary_accuracy: 0.8060\nEpoch 105/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3597 - binary_accuracy: 0.8264 - val_loss: 0.3766 - val_binary_accuracy: 0.8114\nEpoch 106/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3661 - binary_accuracy: 0.8258 - val_loss: 0.3820 - val_binary_accuracy: 0.8108\nEpoch 107/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3623 - binary_accuracy: 0.8229 - val_loss: 0.3807 - val_binary_accuracy: 0.8078\nEpoch 108/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3591 - binary_accuracy: 0.8276 - val_loss: 0.3797 - val_binary_accuracy: 0.8108\nEpoch 109/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3620 - binary_accuracy: 0.8252 - val_loss: 0.3808 - val_binary_accuracy: 0.8108\nEpoch 110/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3680 - binary_accuracy: 0.8254 - val_loss: 0.3816 - val_binary_accuracy: 0.8102\nEpoch 111/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3654 - binary_accuracy: 0.8215 - val_loss: 0.3820 - val_binary_accuracy: 0.8066\nEpoch 112/200\n20/20 [==============================] - 0s 12ms/step - loss: 0.3614 - binary_accuracy: 0.8284 - val_loss: 0.3813 - val_binary_accuracy: 0.8060\nEpoch 1/200\n20/20 [==============================] - 3s 33ms/step - loss: 0.6815 - binary_accuracy: 0.6517 - val_loss: 0.5198 - val_binary_accuracy: 0.7895\nEpoch 2/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.5530 - binary_accuracy: 0.7391 - val_loss: 0.4799 - val_binary_accuracy: 0.7912\nEpoch 3/200\n20/20 [==============================] - 0s 16ms/step - loss: 0.5120 - binary_accuracy: 0.7505 - val_loss: 0.4545 - val_binary_accuracy: 0.7983\nEpoch 4/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.4947 - binary_accuracy: 0.7538 - val_loss: 0.4368 - val_binary_accuracy: 0.8043\nEpoch 5/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.4751 - binary_accuracy: 0.7665 - val_loss: 0.4315 - val_binary_accuracy: 0.8001\nEpoch 6/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.4618 - binary_accuracy: 0.7751 - val_loss: 0.4269 - val_binary_accuracy: 0.8037\nEpoch 7/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.4592 - binary_accuracy: 0.7757 - val_loss: 0.4239 - val_binary_accuracy: 0.7995\nEpoch 8/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.4445 - binary_accuracy: 0.7781 - val_loss: 0.4196 - val_binary_accuracy: 0.8072\nEpoch 9/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.4492 - binary_accuracy: 0.7746 - val_loss: 0.4164 - val_binary_accuracy: 0.8108\nEpoch 10/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.4473 - binary_accuracy: 0.7795 - val_loss: 0.4160 - val_binary_accuracy: 0.8019\nEpoch 11/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.4375 - binary_accuracy: 0.7905 - val_loss: 0.4159 - val_binary_accuracy: 0.8025\nEpoch 12/200\n20/20 [==============================] - 0s 16ms/step - loss: 0.4426 - binary_accuracy: 0.7846 - val_loss: 0.4116 - val_binary_accuracy: 0.8054\nEpoch 13/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.4284 - binary_accuracy: 0.7884 - val_loss: 0.4125 - val_binary_accuracy: 0.8054\nEpoch 14/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.4215 - binary_accuracy: 0.7911 - val_loss: 0.4137 - val_binary_accuracy: 0.8043\nEpoch 15/200\n20/20 [==============================] - 0s 16ms/step - loss: 0.4250 - binary_accuracy: 0.7968 - val_loss: 0.4138 - val_binary_accuracy: 0.8066\nEpoch 16/200\n20/20 [==============================] - 0s 16ms/step - loss: 0.4310 - binary_accuracy: 0.7935 - val_loss: 0.4138 - val_binary_accuracy: 0.8019\nEpoch 17/200\n20/20 [==============================] - 0s 16ms/step - loss: 0.4211 - binary_accuracy: 0.7935 - val_loss: 0.4114 - val_binary_accuracy: 0.8048\nEpoch 18/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.4101 - binary_accuracy: 0.8059 - val_loss: 0.4173 - val_binary_accuracy: 0.8078\nEpoch 19/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.4186 - binary_accuracy: 0.7982 - val_loss: 0.4104 - val_binary_accuracy: 0.8054\nEpoch 20/200\n20/20 [==============================] - 0s 17ms/step - loss: 0.4171 - binary_accuracy: 0.7988 - val_loss: 0.4129 - val_binary_accuracy: 0.8037\nEpoch 21/200\n20/20 [==============================] - 0s 16ms/step - loss: 0.4109 - binary_accuracy: 0.7951 - val_loss: 0.4099 - val_binary_accuracy: 0.8054\nEpoch 22/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.4178 - binary_accuracy: 0.7974 - val_loss: 0.4103 - val_binary_accuracy: 0.8108\nEpoch 23/200\n20/20 [==============================] - 0s 16ms/step - loss: 0.4123 - binary_accuracy: 0.8073 - val_loss: 0.4080 - val_binary_accuracy: 0.8108\nEpoch 24/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.4110 - binary_accuracy: 0.8063 - val_loss: 0.4093 - val_binary_accuracy: 0.8060\nEpoch 25/200\n20/20 [==============================] - 0s 16ms/step - loss: 0.4117 - binary_accuracy: 0.7955 - val_loss: 0.4090 - val_binary_accuracy: 0.8072\nEpoch 26/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3985 - binary_accuracy: 0.8093 - val_loss: 0.4114 - val_binary_accuracy: 0.8013\nEpoch 27/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3994 - binary_accuracy: 0.8061 - val_loss: 0.4117 - val_binary_accuracy: 0.8078\nEpoch 28/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.4009 - binary_accuracy: 0.8059 - val_loss: 0.4077 - val_binary_accuracy: 0.8054\nEpoch 29/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.4062 - binary_accuracy: 0.8014 - val_loss: 0.4062 - val_binary_accuracy: 0.8054\nEpoch 30/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3984 - binary_accuracy: 0.8112 - val_loss: 0.4052 - val_binary_accuracy: 0.8007\nEpoch 31/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.4058 - binary_accuracy: 0.8079 - val_loss: 0.4097 - val_binary_accuracy: 0.8060\nEpoch 32/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.4027 - binary_accuracy: 0.8051 - val_loss: 0.4070 - val_binary_accuracy: 0.8066\nEpoch 33/200\n20/20 [==============================] - 1s 26ms/step - loss: 0.4046 - binary_accuracy: 0.8020 - val_loss: 0.4023 - val_binary_accuracy: 0.7983\nEpoch 34/200\n20/20 [==============================] - 1s 33ms/step - loss: 0.4028 - binary_accuracy: 0.8059 - val_loss: 0.4051 - val_binary_accuracy: 0.8060\nEpoch 35/200\n20/20 [==============================] - 0s 16ms/step - loss: 0.3972 - binary_accuracy: 0.8075 - val_loss: 0.4068 - val_binary_accuracy: 0.8096\nEpoch 36/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3928 - binary_accuracy: 0.8124 - val_loss: 0.4041 - val_binary_accuracy: 0.8084\nEpoch 37/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3930 - binary_accuracy: 0.8095 - val_loss: 0.4073 - val_binary_accuracy: 0.8043\nEpoch 38/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3935 - binary_accuracy: 0.8118 - val_loss: 0.4025 - val_binary_accuracy: 0.8043\nEpoch 39/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3910 - binary_accuracy: 0.8083 - val_loss: 0.4047 - val_binary_accuracy: 0.8108\nEpoch 40/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3954 - binary_accuracy: 0.8116 - val_loss: 0.4022 - val_binary_accuracy: 0.8048\nEpoch 41/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3985 - binary_accuracy: 0.8099 - val_loss: 0.4030 - val_binary_accuracy: 0.8078\nEpoch 42/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3931 - binary_accuracy: 0.8174 - val_loss: 0.4020 - val_binary_accuracy: 0.8066\nEpoch 43/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3888 - binary_accuracy: 0.8130 - val_loss: 0.4074 - val_binary_accuracy: 0.8084\nEpoch 44/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3946 - binary_accuracy: 0.8057 - val_loss: 0.4022 - val_binary_accuracy: 0.8054\nEpoch 45/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3868 - binary_accuracy: 0.8150 - val_loss: 0.4003 - val_binary_accuracy: 0.8066\nEpoch 46/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3967 - binary_accuracy: 0.8085 - val_loss: 0.4012 - val_binary_accuracy: 0.8066\nEpoch 47/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3938 - binary_accuracy: 0.8079 - val_loss: 0.3987 - val_binary_accuracy: 0.8048\nEpoch 48/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3908 - binary_accuracy: 0.8112 - val_loss: 0.3979 - val_binary_accuracy: 0.8066\nEpoch 49/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3891 - binary_accuracy: 0.8032 - val_loss: 0.3992 - val_binary_accuracy: 0.8048\nEpoch 50/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3864 - binary_accuracy: 0.8178 - val_loss: 0.4022 - val_binary_accuracy: 0.8084\nEpoch 51/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3900 - binary_accuracy: 0.8107 - val_loss: 0.3984 - val_binary_accuracy: 0.8114\nEpoch 52/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3876 - binary_accuracy: 0.8095 - val_loss: 0.3991 - val_binary_accuracy: 0.8102\nEpoch 53/200\n20/20 [==============================] - 0s 16ms/step - loss: 0.3888 - binary_accuracy: 0.8112 - val_loss: 0.3972 - val_binary_accuracy: 0.8084\nEpoch 54/200\n20/20 [==============================] - 0s 19ms/step - loss: 0.3860 - binary_accuracy: 0.8107 - val_loss: 0.3978 - val_binary_accuracy: 0.8090\nEpoch 55/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3903 - binary_accuracy: 0.8045 - val_loss: 0.3961 - val_binary_accuracy: 0.8102\nEpoch 56/200\n20/20 [==============================] - 0s 16ms/step - loss: 0.3833 - binary_accuracy: 0.8130 - val_loss: 0.3963 - val_binary_accuracy: 0.8131\nEpoch 57/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3847 - binary_accuracy: 0.8164 - val_loss: 0.3936 - val_binary_accuracy: 0.8078\nEpoch 58/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3809 - binary_accuracy: 0.8156 - val_loss: 0.3943 - val_binary_accuracy: 0.8096\nEpoch 59/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3843 - binary_accuracy: 0.8132 - val_loss: 0.3938 - val_binary_accuracy: 0.8090\nEpoch 60/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3771 - binary_accuracy: 0.8231 - val_loss: 0.3989 - val_binary_accuracy: 0.8096\nEpoch 61/200\n20/20 [==============================] - 0s 16ms/step - loss: 0.3796 - binary_accuracy: 0.8154 - val_loss: 0.3934 - val_binary_accuracy: 0.8072\nEpoch 62/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3816 - binary_accuracy: 0.8166 - val_loss: 0.3964 - val_binary_accuracy: 0.8084\nEpoch 63/200\n20/20 [==============================] - 0s 16ms/step - loss: 0.3781 - binary_accuracy: 0.8148 - val_loss: 0.3911 - val_binary_accuracy: 0.8125\nEpoch 64/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3852 - binary_accuracy: 0.8120 - val_loss: 0.3913 - val_binary_accuracy: 0.8048\nEpoch 65/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3860 - binary_accuracy: 0.8187 - val_loss: 0.3894 - val_binary_accuracy: 0.8119\nEpoch 66/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3834 - binary_accuracy: 0.8138 - val_loss: 0.3894 - val_binary_accuracy: 0.8179\nEpoch 67/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3815 - binary_accuracy: 0.8142 - val_loss: 0.3876 - val_binary_accuracy: 0.8125\nEpoch 68/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3787 - binary_accuracy: 0.8122 - val_loss: 0.3843 - val_binary_accuracy: 0.8137\nEpoch 69/200\n20/20 [==============================] - 0s 16ms/step - loss: 0.3764 - binary_accuracy: 0.8144 - val_loss: 0.3884 - val_binary_accuracy: 0.8054\nEpoch 70/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3773 - binary_accuracy: 0.8172 - val_loss: 0.3910 - val_binary_accuracy: 0.8066\nEpoch 71/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3758 - binary_accuracy: 0.8170 - val_loss: 0.3869 - val_binary_accuracy: 0.8108\nEpoch 72/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3773 - binary_accuracy: 0.8183 - val_loss: 0.3869 - val_binary_accuracy: 0.8078\nEpoch 73/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3773 - binary_accuracy: 0.8179 - val_loss: 0.3875 - val_binary_accuracy: 0.8096\nEpoch 74/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3821 - binary_accuracy: 0.8146 - val_loss: 0.3872 - val_binary_accuracy: 0.8072\nEpoch 75/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3782 - binary_accuracy: 0.8164 - val_loss: 0.3868 - val_binary_accuracy: 0.8090\nEpoch 76/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3747 - binary_accuracy: 0.8164 - val_loss: 0.3849 - val_binary_accuracy: 0.8108\nEpoch 77/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3677 - binary_accuracy: 0.8268 - val_loss: 0.3859 - val_binary_accuracy: 0.8096\nEpoch 78/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3766 - binary_accuracy: 0.8166 - val_loss: 0.3862 - val_binary_accuracy: 0.8114\nEpoch 79/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3703 - binary_accuracy: 0.8201 - val_loss: 0.3869 - val_binary_accuracy: 0.8066\nEpoch 80/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3750 - binary_accuracy: 0.8154 - val_loss: 0.3855 - val_binary_accuracy: 0.8096\nEpoch 81/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3754 - binary_accuracy: 0.8193 - val_loss: 0.3846 - val_binary_accuracy: 0.8043\nEpoch 82/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3696 - binary_accuracy: 0.8203 - val_loss: 0.3818 - val_binary_accuracy: 0.8102\nEpoch 83/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3695 - binary_accuracy: 0.8227 - val_loss: 0.3824 - val_binary_accuracy: 0.8114\nEpoch 84/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3731 - binary_accuracy: 0.8170 - val_loss: 0.3839 - val_binary_accuracy: 0.8108\nEpoch 85/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3705 - binary_accuracy: 0.8211 - val_loss: 0.3859 - val_binary_accuracy: 0.8072\nEpoch 86/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3685 - binary_accuracy: 0.8221 - val_loss: 0.3840 - val_binary_accuracy: 0.8108\nEpoch 87/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3697 - binary_accuracy: 0.8178 - val_loss: 0.3856 - val_binary_accuracy: 0.8096\nEpoch 88/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3678 - binary_accuracy: 0.8199 - val_loss: 0.3840 - val_binary_accuracy: 0.8137\nEpoch 89/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3663 - binary_accuracy: 0.8211 - val_loss: 0.3891 - val_binary_accuracy: 0.8060\nEpoch 90/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3687 - binary_accuracy: 0.8164 - val_loss: 0.3846 - val_binary_accuracy: 0.8125\nEpoch 91/200\n20/20 [==============================] - 0s 18ms/step - loss: 0.3692 - binary_accuracy: 0.8193 - val_loss: 0.3854 - val_binary_accuracy: 0.8108\nEpoch 92/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3703 - binary_accuracy: 0.8233 - val_loss: 0.3804 - val_binary_accuracy: 0.8190\nEpoch 93/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3675 - binary_accuracy: 0.8211 - val_loss: 0.3848 - val_binary_accuracy: 0.8066\nEpoch 94/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3729 - binary_accuracy: 0.8156 - val_loss: 0.3803 - val_binary_accuracy: 0.8131\nEpoch 95/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3660 - binary_accuracy: 0.8250 - val_loss: 0.3840 - val_binary_accuracy: 0.8149\nEpoch 96/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3641 - binary_accuracy: 0.8247 - val_loss: 0.3822 - val_binary_accuracy: 0.8161\nEpoch 97/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3542 - binary_accuracy: 0.8256 - val_loss: 0.3828 - val_binary_accuracy: 0.8149\nEpoch 98/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3699 - binary_accuracy: 0.8201 - val_loss: 0.3826 - val_binary_accuracy: 0.8108\nEpoch 99/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3607 - binary_accuracy: 0.8221 - val_loss: 0.3792 - val_binary_accuracy: 0.8202\nEpoch 100/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3643 - binary_accuracy: 0.8227 - val_loss: 0.3833 - val_binary_accuracy: 0.8108\nEpoch 101/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3667 - binary_accuracy: 0.8233 - val_loss: 0.3828 - val_binary_accuracy: 0.8084\nEpoch 102/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3689 - binary_accuracy: 0.8197 - val_loss: 0.3808 - val_binary_accuracy: 0.8119\nEpoch 103/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3591 - binary_accuracy: 0.8260 - val_loss: 0.3827 - val_binary_accuracy: 0.8084\nEpoch 104/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3569 - binary_accuracy: 0.8247 - val_loss: 0.3882 - val_binary_accuracy: 0.8037\nEpoch 105/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3613 - binary_accuracy: 0.8284 - val_loss: 0.3862 - val_binary_accuracy: 0.8037\nEpoch 106/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3572 - binary_accuracy: 0.8288 - val_loss: 0.3838 - val_binary_accuracy: 0.8072\nEpoch 107/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3596 - binary_accuracy: 0.8260 - val_loss: 0.3885 - val_binary_accuracy: 0.8019\nEpoch 108/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3615 - binary_accuracy: 0.8264 - val_loss: 0.3858 - val_binary_accuracy: 0.8054\nEpoch 109/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3634 - binary_accuracy: 0.8231 - val_loss: 0.3839 - val_binary_accuracy: 0.8031\nEpoch 110/200\n20/20 [==============================] - 0s 16ms/step - loss: 0.3567 - binary_accuracy: 0.8237 - val_loss: 0.3824 - val_binary_accuracy: 0.8096\nEpoch 111/200\n20/20 [==============================] - 0s 17ms/step - loss: 0.3597 - binary_accuracy: 0.8243 - val_loss: 0.3843 - val_binary_accuracy: 0.8060\nEpoch 112/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3603 - binary_accuracy: 0.8209 - val_loss: 0.3856 - val_binary_accuracy: 0.8013\nEpoch 113/200\n20/20 [==============================] - 0s 16ms/step - loss: 0.3581 - binary_accuracy: 0.8249 - val_loss: 0.3836 - val_binary_accuracy: 0.8102\nEpoch 114/200\n20/20 [==============================] - 0s 14ms/step - loss: 0.3656 - binary_accuracy: 0.8237 - val_loss: 0.3867 - val_binary_accuracy: 0.8031\nEpoch 115/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3598 - binary_accuracy: 0.8219 - val_loss: 0.3857 - val_binary_accuracy: 0.8060\nEpoch 116/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3601 - binary_accuracy: 0.8221 - val_loss: 0.3827 - val_binary_accuracy: 0.8072\nEpoch 117/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3591 - binary_accuracy: 0.8292 - val_loss: 0.3801 - val_binary_accuracy: 0.8143\nEpoch 118/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3564 - binary_accuracy: 0.8280 - val_loss: 0.3815 - val_binary_accuracy: 0.8096\nEpoch 119/200\n20/20 [==============================] - 0s 15ms/step - loss: 0.3509 - binary_accuracy: 0.8292 - val_loss: 0.3828 - val_binary_accuracy: 0.8072\n","output_type":"stream"}]},{"cell_type":"code","source":"test_trans = preprocessor.fit_transform(test_data)\npredictions = pd.DataFrame()\nfor i in range(len(models)):\n    y_pred = models[i].predict(test_trans)\n    pred = []\n    for element in y_pred:\n        pred.append(element[0])\n    predictions[i] = pred\npredictions[1200:1225]\n","metadata":{"execution":{"iopub.status.busy":"2022-11-28T00:40:36.813082Z","iopub.execute_input":"2022-11-28T00:40:36.813432Z","iopub.status.idle":"2022-11-28T00:40:39.592997Z","shell.execute_reply.started":"2022-11-28T00:40:36.813401Z","shell.execute_reply":"2022-11-28T00:40:39.591980Z"},"trusted":true},"execution_count":87,"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"             0         1         2         3         4         5\n1200  0.290894  0.216618  0.199270  0.227351  0.182353  0.188197\n1201  0.992188  0.987797  0.991123  0.992398  0.990803  0.983388\n1202  0.992614  0.991407  0.992136  0.995025  0.996663  0.997755\n1203  0.967100  0.963822  0.958111  0.975473  0.968943  0.978483\n1204  0.773736  0.674312  0.680142  0.688257  0.709936  0.661737\n1205  0.400955  0.485123  0.479427  0.392887  0.437451  0.379233\n1206  0.366297  0.339609  0.363569  0.313537  0.254885  0.231306\n1207  0.985650  0.985958  0.995904  0.993663  0.994260  0.982537\n1208  0.614293  0.648242  0.580064  0.543177  0.488559  0.489829\n1209  0.136347  0.143696  0.127214  0.123744  0.101352  0.126525\n1210  0.500187  0.454876  0.255805  0.397316  0.337169  0.318568\n1211  0.996068  0.993745  0.994287  0.997090  0.996087  0.996886\n1212  0.672525  0.705495  0.686069  0.650863  0.658596  0.572013\n1213  0.364075  0.377183  0.360500  0.308571  0.338963  0.308098\n1214  0.480781  0.477774  0.515375  0.465308  0.483101  0.476618\n1215  0.746467  0.924694  0.957045  0.777988  0.924866  0.827413\n1216  0.990185  0.972616  0.979149  0.986004  0.983940  0.965173\n1217  0.592677  0.646191  0.568185  0.530030  0.479167  0.478249\n1218  0.552536  0.637070  0.549633  0.525051  0.472828  0.482269\n1219  0.080075  0.061018  0.063193  0.067063  0.061042  0.050146\n1220  0.458961  0.457545  0.497259  0.449832  0.468781  0.458318\n1221  0.963434  0.955939  0.955554  0.974534  0.965748  0.976475\n1222  0.310672  0.280379  0.305590  0.275243  0.289788  0.281214\n1223  0.972512  0.971617  0.985661  0.980554  0.976084  0.961108\n1224  0.986247  0.984988  0.990953  0.993125  0.989644  0.988490","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1200</th>\n      <td>0.290894</td>\n      <td>0.216618</td>\n      <td>0.199270</td>\n      <td>0.227351</td>\n      <td>0.182353</td>\n      <td>0.188197</td>\n    </tr>\n    <tr>\n      <th>1201</th>\n      <td>0.992188</td>\n      <td>0.987797</td>\n      <td>0.991123</td>\n      <td>0.992398</td>\n      <td>0.990803</td>\n      <td>0.983388</td>\n    </tr>\n    <tr>\n      <th>1202</th>\n      <td>0.992614</td>\n      <td>0.991407</td>\n      <td>0.992136</td>\n      <td>0.995025</td>\n      <td>0.996663</td>\n      <td>0.997755</td>\n    </tr>\n    <tr>\n      <th>1203</th>\n      <td>0.967100</td>\n      <td>0.963822</td>\n      <td>0.958111</td>\n      <td>0.975473</td>\n      <td>0.968943</td>\n      <td>0.978483</td>\n    </tr>\n    <tr>\n      <th>1204</th>\n      <td>0.773736</td>\n      <td>0.674312</td>\n      <td>0.680142</td>\n      <td>0.688257</td>\n      <td>0.709936</td>\n      <td>0.661737</td>\n    </tr>\n    <tr>\n      <th>1205</th>\n      <td>0.400955</td>\n      <td>0.485123</td>\n      <td>0.479427</td>\n      <td>0.392887</td>\n      <td>0.437451</td>\n      <td>0.379233</td>\n    </tr>\n    <tr>\n      <th>1206</th>\n      <td>0.366297</td>\n      <td>0.339609</td>\n      <td>0.363569</td>\n      <td>0.313537</td>\n      <td>0.254885</td>\n      <td>0.231306</td>\n    </tr>\n    <tr>\n      <th>1207</th>\n      <td>0.985650</td>\n      <td>0.985958</td>\n      <td>0.995904</td>\n      <td>0.993663</td>\n      <td>0.994260</td>\n      <td>0.982537</td>\n    </tr>\n    <tr>\n      <th>1208</th>\n      <td>0.614293</td>\n      <td>0.648242</td>\n      <td>0.580064</td>\n      <td>0.543177</td>\n      <td>0.488559</td>\n      <td>0.489829</td>\n    </tr>\n    <tr>\n      <th>1209</th>\n      <td>0.136347</td>\n      <td>0.143696</td>\n      <td>0.127214</td>\n      <td>0.123744</td>\n      <td>0.101352</td>\n      <td>0.126525</td>\n    </tr>\n    <tr>\n      <th>1210</th>\n      <td>0.500187</td>\n      <td>0.454876</td>\n      <td>0.255805</td>\n      <td>0.397316</td>\n      <td>0.337169</td>\n      <td>0.318568</td>\n    </tr>\n    <tr>\n      <th>1211</th>\n      <td>0.996068</td>\n      <td>0.993745</td>\n      <td>0.994287</td>\n      <td>0.997090</td>\n      <td>0.996087</td>\n      <td>0.996886</td>\n    </tr>\n    <tr>\n      <th>1212</th>\n      <td>0.672525</td>\n      <td>0.705495</td>\n      <td>0.686069</td>\n      <td>0.650863</td>\n      <td>0.658596</td>\n      <td>0.572013</td>\n    </tr>\n    <tr>\n      <th>1213</th>\n      <td>0.364075</td>\n      <td>0.377183</td>\n      <td>0.360500</td>\n      <td>0.308571</td>\n      <td>0.338963</td>\n      <td>0.308098</td>\n    </tr>\n    <tr>\n      <th>1214</th>\n      <td>0.480781</td>\n      <td>0.477774</td>\n      <td>0.515375</td>\n      <td>0.465308</td>\n      <td>0.483101</td>\n      <td>0.476618</td>\n    </tr>\n    <tr>\n      <th>1215</th>\n      <td>0.746467</td>\n      <td>0.924694</td>\n      <td>0.957045</td>\n      <td>0.777988</td>\n      <td>0.924866</td>\n      <td>0.827413</td>\n    </tr>\n    <tr>\n      <th>1216</th>\n      <td>0.990185</td>\n      <td>0.972616</td>\n      <td>0.979149</td>\n      <td>0.986004</td>\n      <td>0.983940</td>\n      <td>0.965173</td>\n    </tr>\n    <tr>\n      <th>1217</th>\n      <td>0.592677</td>\n      <td>0.646191</td>\n      <td>0.568185</td>\n      <td>0.530030</td>\n      <td>0.479167</td>\n      <td>0.478249</td>\n    </tr>\n    <tr>\n      <th>1218</th>\n      <td>0.552536</td>\n      <td>0.637070</td>\n      <td>0.549633</td>\n      <td>0.525051</td>\n      <td>0.472828</td>\n      <td>0.482269</td>\n    </tr>\n    <tr>\n      <th>1219</th>\n      <td>0.080075</td>\n      <td>0.061018</td>\n      <td>0.063193</td>\n      <td>0.067063</td>\n      <td>0.061042</td>\n      <td>0.050146</td>\n    </tr>\n    <tr>\n      <th>1220</th>\n      <td>0.458961</td>\n      <td>0.457545</td>\n      <td>0.497259</td>\n      <td>0.449832</td>\n      <td>0.468781</td>\n      <td>0.458318</td>\n    </tr>\n    <tr>\n      <th>1221</th>\n      <td>0.963434</td>\n      <td>0.955939</td>\n      <td>0.955554</td>\n      <td>0.974534</td>\n      <td>0.965748</td>\n      <td>0.976475</td>\n    </tr>\n    <tr>\n      <th>1222</th>\n      <td>0.310672</td>\n      <td>0.280379</td>\n      <td>0.305590</td>\n      <td>0.275243</td>\n      <td>0.289788</td>\n      <td>0.281214</td>\n    </tr>\n    <tr>\n      <th>1223</th>\n      <td>0.972512</td>\n      <td>0.971617</td>\n      <td>0.985661</td>\n      <td>0.980554</td>\n      <td>0.976084</td>\n      <td>0.961108</td>\n    </tr>\n    <tr>\n      <th>1224</th>\n      <td>0.986247</td>\n      <td>0.984988</td>\n      <td>0.990953</td>\n      <td>0.993125</td>\n      <td>0.989644</td>\n      <td>0.988490</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"predictions['final_prediction'] = predictions.mean(axis=1)\npredictions","metadata":{"execution":{"iopub.status.busy":"2022-11-28T00:40:39.594526Z","iopub.execute_input":"2022-11-28T00:40:39.595141Z","iopub.status.idle":"2022-11-28T00:40:39.619231Z","shell.execute_reply.started":"2022-11-28T00:40:39.595104Z","shell.execute_reply":"2022-11-28T00:40:39.617829Z"},"trusted":true},"execution_count":88,"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"             0         1         2         3         4         5  \\\n0     0.426947  0.429377  0.465584  0.431804  0.417445  0.440873   \n1     0.012523  0.024383  0.032583  0.029346  0.031381  0.024825   \n2     0.999023  0.998907  0.996854  0.998882  0.998851  0.998135   \n3     0.999038  0.997073  0.997202  0.999196  0.993644  0.994227   \n4     0.470849  0.428305  0.517409  0.476567  0.533400  0.368122   \n...        ...       ...       ...       ...       ...       ...   \n4272  0.527622  0.728096  0.561856  0.483972  0.421227  0.470249   \n4273  0.860412  0.622148  0.886446  0.658958  0.775482  0.926116   \n4274  0.980222  0.966506  0.971829  0.962344  0.981177  0.967901   \n4275  0.877686  0.812229  0.832534  0.711126  0.815272  0.767040   \n4276  0.550850  0.729280  0.564321  0.551902  0.523236  0.496956   \n\n      final_prediction  \n0             0.435338  \n1             0.025840  \n2             0.998442  \n3             0.996730  \n4             0.465775  \n...                ...  \n4272          0.532171  \n4273          0.788261  \n4274          0.971663  \n4275          0.802648  \n4276          0.569424  \n\n[4277 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>final_prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.426947</td>\n      <td>0.429377</td>\n      <td>0.465584</td>\n      <td>0.431804</td>\n      <td>0.417445</td>\n      <td>0.440873</td>\n      <td>0.435338</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.012523</td>\n      <td>0.024383</td>\n      <td>0.032583</td>\n      <td>0.029346</td>\n      <td>0.031381</td>\n      <td>0.024825</td>\n      <td>0.025840</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.999023</td>\n      <td>0.998907</td>\n      <td>0.996854</td>\n      <td>0.998882</td>\n      <td>0.998851</td>\n      <td>0.998135</td>\n      <td>0.998442</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.999038</td>\n      <td>0.997073</td>\n      <td>0.997202</td>\n      <td>0.999196</td>\n      <td>0.993644</td>\n      <td>0.994227</td>\n      <td>0.996730</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.470849</td>\n      <td>0.428305</td>\n      <td>0.517409</td>\n      <td>0.476567</td>\n      <td>0.533400</td>\n      <td>0.368122</td>\n      <td>0.465775</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4272</th>\n      <td>0.527622</td>\n      <td>0.728096</td>\n      <td>0.561856</td>\n      <td>0.483972</td>\n      <td>0.421227</td>\n      <td>0.470249</td>\n      <td>0.532171</td>\n    </tr>\n    <tr>\n      <th>4273</th>\n      <td>0.860412</td>\n      <td>0.622148</td>\n      <td>0.886446</td>\n      <td>0.658958</td>\n      <td>0.775482</td>\n      <td>0.926116</td>\n      <td>0.788261</td>\n    </tr>\n    <tr>\n      <th>4274</th>\n      <td>0.980222</td>\n      <td>0.966506</td>\n      <td>0.971829</td>\n      <td>0.962344</td>\n      <td>0.981177</td>\n      <td>0.967901</td>\n      <td>0.971663</td>\n    </tr>\n    <tr>\n      <th>4275</th>\n      <td>0.877686</td>\n      <td>0.812229</td>\n      <td>0.832534</td>\n      <td>0.711126</td>\n      <td>0.815272</td>\n      <td>0.767040</td>\n      <td>0.802648</td>\n    </tr>\n    <tr>\n      <th>4276</th>\n      <td>0.550850</td>\n      <td>0.729280</td>\n      <td>0.564321</td>\n      <td>0.551902</td>\n      <td>0.523236</td>\n      <td>0.496956</td>\n      <td>0.569424</td>\n    </tr>\n  </tbody>\n</table>\n<p>4277 rows  7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"f = open ('/kaggle/working/submission.csv','w')\nf.write('PassengerId,Transported\\n')\nfor i in range(len(y_pred)):\n    f.write(test_data.index[i])\n    f.write(',')\n    f.write(str(predictions['final_prediction'][i] > 0.5))\n    f.write('\\n')\nf.close()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T00:40:39.620748Z","iopub.execute_input":"2022-11-28T00:40:39.621085Z","iopub.status.idle":"2022-11-28T00:40:39.688175Z","shell.execute_reply.started":"2022-11-28T00:40:39.621056Z","shell.execute_reply":"2022-11-28T00:40:39.686385Z"},"trusted":true},"execution_count":89,"outputs":[]}]}